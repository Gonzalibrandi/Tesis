{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-yVntr",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "FAISS-yXWJ4",
            "inputTypes": [
              "Message"
            ],
            "type": "query"
          }
        },
        "id": "xy-edge__ChatInput-yVntr{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yVntrœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-FAISS-yXWJ4{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-yXWJ4œ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}",
        "selected": false,
        "source": "ChatInput-yVntr",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yVntrœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "FAISS-yXWJ4",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-yXWJ4œ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-yVntr",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "FAISS-0oYcF",
            "inputTypes": [
              "Message"
            ],
            "type": "query"
          }
        },
        "id": "xy-edge__ChatInput-yVntr{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yVntrœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-FAISS-0oYcF{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-0oYcFœ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}",
        "selected": false,
        "source": "ChatInput-yVntr",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yVntrœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "FAISS-0oYcF",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-0oYcFœ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DataFrameMerger",
            "id": "CustomComponent-n51Gu",
            "name": "combined_df",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "CustomComponent-N1Dmp",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-n51Gu{œdataTypeœ:œDataFrameMergerœ,œidœ:œCustomComponent-n51Guœ,œnameœ:œcombined_dfœ,œoutput_typesœ:[œDataFrameœ]}-CustomComponent-N1Dmp{œfieldNameœ:œinput_dataœ,œidœ:œCustomComponent-N1Dmpœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-n51Gu",
        "sourceHandle": "{œdataTypeœ:œDataFrameMergerœ,œidœ:œCustomComponent-n51Guœ,œnameœ:œcombined_dfœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "CustomComponent-N1Dmp",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œCustomComponent-N1Dmpœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-yVntr",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt-7vMII",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ChatInput-yVntr{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yVntrœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-7vMII{œfieldNameœ:œquestionœ,œidœ:œPrompt-7vMIIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-yVntr",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yVntrœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-7vMII",
        "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œPrompt-7vMIIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LocalHuggingFaceEmbeddings",
            "id": "LocalHuggingFaceEmbeddings-O3z78",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "FAISS-yXWJ4",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__LocalHuggingFaceEmbeddings-O3z78{œdataTypeœ:œLocalHuggingFaceEmbeddingsœ,œidœ:œLocalHuggingFaceEmbeddings-O3z78œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-FAISS-yXWJ4{œfieldNameœ:œembeddingœ,œidœ:œFAISS-yXWJ4œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LocalHuggingFaceEmbeddings-O3z78",
        "sourceHandle": "{œdataTypeœ:œLocalHuggingFaceEmbeddingsœ,œidœ:œLocalHuggingFaceEmbeddings-O3z78œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "FAISS-yXWJ4",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œFAISS-yXWJ4œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LocalHuggingFaceEmbeddings",
            "id": "LocalHuggingFaceEmbeddings-O3z78",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "FAISS-0oYcF",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__LocalHuggingFaceEmbeddings-O3z78{œdataTypeœ:œLocalHuggingFaceEmbeddingsœ,œidœ:œLocalHuggingFaceEmbeddings-O3z78œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-FAISS-0oYcF{œfieldNameœ:œembeddingœ,œidœ:œFAISS-0oYcFœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LocalHuggingFaceEmbeddings-O3z78",
        "sourceHandle": "{œdataTypeœ:œLocalHuggingFaceEmbeddingsœ,œidœ:œLocalHuggingFaceEmbeddings-O3z78œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "FAISS-0oYcF",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œFAISS-0oYcFœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "parser",
            "id": "CustomComponent-N1Dmp",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "structured_data_text",
            "id": "CustomComponent-HweCC",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__CustomComponent-N1Dmp{œdataTypeœ:œparserœ,œidœ:œCustomComponent-N1Dmpœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-HweCC{œfieldNameœ:œstructured_data_textœ,œidœ:œCustomComponent-HweCCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CustomComponent-N1Dmp",
        "sourceHandle": "{œdataTypeœ:œparserœ,œidœ:œCustomComponent-N1Dmpœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-HweCC",
        "targetHandle": "{œfieldNameœ:œstructured_data_textœ,œidœ:œCustomComponent-HweCCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FAISS",
            "id": "FAISS-0oYcF",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_dataframe",
            "id": "ConditionalRouter-RZ4gB",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__FAISS-0oYcF{œdataTypeœ:œFAISSœ,œidœ:œFAISS-0oYcFœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-ConditionalRouter-RZ4gB{œfieldNameœ:œinput_dataframeœ,œidœ:œConditionalRouter-RZ4gBœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "FAISS-0oYcF",
        "sourceHandle": "{œdataTypeœ:œFAISSœ,œidœ:œFAISS-0oYcFœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ConditionalRouter-RZ4gB",
        "targetHandle": "{œfieldNameœ:œinput_dataframeœ,œidœ:œConditionalRouter-RZ4gBœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-RZ4gB",
            "name": "df_result",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "dataframe_2",
            "id": "CustomComponent-n51Gu",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-RZ4gB{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-RZ4gBœ,œnameœ:œdf_resultœ,œoutput_typesœ:[œDataFrameœ]}-CustomComponent-n51Gu{œfieldNameœ:œdataframe_2œ,œidœ:œCustomComponent-n51Guœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-RZ4gB",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-RZ4gBœ,œnameœ:œdf_resultœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "CustomComponent-n51Gu",
        "targetHandle": "{œfieldNameœ:œdataframe_2œ,œidœ:œCustomComponent-n51Guœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FAISS",
            "id": "FAISS-yXWJ4",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_dataframe",
            "id": "ConditionalRouter-92JKj",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__FAISS-yXWJ4{œdataTypeœ:œFAISSœ,œidœ:œFAISS-yXWJ4œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-ConditionalRouter-92JKj{œfieldNameœ:œinput_dataframeœ,œidœ:œConditionalRouter-92JKjœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "FAISS-yXWJ4",
        "sourceHandle": "{œdataTypeœ:œFAISSœ,œidœ:œFAISS-yXWJ4œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ConditionalRouter-92JKj",
        "targetHandle": "{œfieldNameœ:œinput_dataframeœ,œidœ:œConditionalRouter-92JKjœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-92JKj",
            "name": "df_result",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "dataframe_1",
            "id": "CustomComponent-n51Gu",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-92JKj{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-92JKjœ,œnameœ:œdf_resultœ,œoutput_typesœ:[œDataFrameœ]}-CustomComponent-n51Gu{œfieldNameœ:œdataframe_1œ,œidœ:œCustomComponent-n51Guœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-92JKj",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-92JKjœ,œnameœ:œdf_resultœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "CustomComponent-n51Gu",
        "targetHandle": "{œfieldNameœ:œdataframe_1œ,œidœ:œCustomComponent-n51Guœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-7vMII",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-4TVDv",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-7vMII{œdataTypeœ:œPromptœ,œidœ:œPrompt-7vMIIœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-4TVDv{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-4TVDvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-7vMII",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-7vMIIœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-4TVDv",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-4TVDvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ContextTextMerger",
            "id": "CustomComponent-HweCC",
            "name": "unified_context",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-4TVDv",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__CustomComponent-HweCC{œdataTypeœ:œContextTextMergerœ,œidœ:œCustomComponent-HweCCœ,œnameœ:œunified_contextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-4TVDv{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-4TVDvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CustomComponent-HweCC",
        "sourceHandle": "{œdataTypeœ:œContextTextMergerœ,œidœ:œCustomComponent-HweCCœ,œnameœ:œunified_contextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-4TVDv",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-4TVDvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-4TVDv",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-KRmEh",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIModel-4TVDv{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-4TVDvœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-KRmEh{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-KRmEhœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-4TVDv",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-4TVDvœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-KRmEh",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-KRmEhœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "data": {
          "sourceHandle": {
            "dataType": "JigsawStackAISearch",
            "id": "JigsawStackAISearch-OqFI6",
            "name": "search_results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "CustomComponent-pE1Im",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__JigsawStackAISearch-OqFI6{œdataTypeœ:œJigsawStackAISearchœ,œidœ:œJigsawStackAISearch-OqFI6œ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-CustomComponent-pE1Im{œfieldNameœ:œinput_dataœ,œidœ:œCustomComponent-pE1Imœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "JigsawStackAISearch-OqFI6",
        "sourceHandle": "{œdataTypeœ:œJigsawStackAISearchœ,œidœ:œJigsawStackAISearch-OqFI6œ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-pE1Im",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œCustomComponent-pE1Imœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-yVntr",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "query",
            "id": "JigsawStackAISearch-OqFI6",
            "inputTypes": [
              "Message"
            ],
            "type": "query"
          }
        },
        "id": "xy-edge__ChatInput-yVntr{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yVntrœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-JigsawStackAISearch-OqFI6{œfieldNameœ:œqueryœ,œidœ:œJigsawStackAISearch-OqFI6œ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}",
        "selected": false,
        "source": "ChatInput-yVntr",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yVntrœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "JigsawStackAISearch-OqFI6",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œJigsawStackAISearch-OqFI6œ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}"
      },
      {
        "animated": false,
        "data": {
          "sourceHandle": {
            "dataType": "JigsawStackAIParser",
            "id": "CustomComponent-pE1Im",
            "name": "formatted_context_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "web_search_context",
            "id": "CustomComponent-HweCC",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__CustomComponent-pE1Im{œdataTypeœ:œJigsawStackAIParserœ,œidœ:œCustomComponent-pE1Imœ,œnameœ:œformatted_context_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-HweCC{œfieldNameœ:œweb_search_contextœ,œidœ:œCustomComponent-HweCCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CustomComponent-pE1Im",
        "sourceHandle": "{œdataTypeœ:œJigsawStackAIParserœ,œidœ:œCustomComponent-pE1Imœ,œnameœ:œformatted_context_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-HweCC",
        "targetHandle": "{œfieldNameœ:œweb_search_contextœ,œidœ:œCustomComponent-HweCCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "ChatInput-yVntr",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "https://docs.langflow.org/components-io#chat-input",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-input\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        # Ensure files is a list and filter out empty/None values\n        files = self.files if self.files else []\n        if files and not isinstance(files, list):\n            files = [files]\n        files = [f for f in files if f is not None and f != \"\"]\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=files,\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-yVntr",
        "measured": {
          "height": 203,
          "width": 320
        },
        "position": {
          "x": 299.413755346691,
          "y": 94.78801637837807
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FAISS-yXWJ4",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "vectorstores",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "FAISS Vector Store with search capabilities",
            "display_name": "FAISS",
            "documentation": "",
            "edited": false,
            "field_order": [
              "index_name",
              "persist_directory",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "allow_dangerous_deserialization",
              "embedding",
              "number_of_results"
            ],
            "frozen": false,
            "icon": "FAISS",
            "key": "FAISS",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "group_outputs": false,
                "method": "search_documents",
                "name": "search_results",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "method": "as_dataframe",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 1.3256846433581093e-17,
            "template": {
              "_type": "Component",
              "allow_dangerous_deserialization": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Allow Dangerous Deserialization",
                "dynamic": false,
                "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
                "list": false,
                "list_add_label": "Add More",
                "name": "allow_dangerous_deserialization",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pathlib import Path\n\nfrom langchain_community.vectorstores import FAISS\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import BoolInput, HandleInput, IntInput, StrInput\nfrom langflow.schema.data import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"FAISS Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"langflow_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. \"\n            \"Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    @staticmethod\n    def resolve_path(path: str) -> str:\n        \"\"\"Resolve the path relative to the Langflow root.\n\n        Args:\n            path: The path to resolve\n        Returns:\n            str: The resolved path as a string\n        \"\"\"\n        return str(Path(path).resolve())\n\n    def get_persist_directory(self) -> Path:\n        \"\"\"Returns the resolved persist directory path or the current directory if not set.\"\"\"\n        if self.persist_directory:\n            return Path(self.resolve_path(self.persist_directory))\n        return Path()\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> FAISS:\n        \"\"\"Builds the FAISS object.\"\"\"\n        path = self.get_persist_directory()\n        path.mkdir(parents=True, exist_ok=True)\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n        return faiss\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search for documents in the FAISS vector store.\"\"\"\n        path = self.get_persist_directory()\n        index_path = path / f\"{self.index_name}.faiss\"\n\n        if not index_path.exists():\n            vector_store = self.build_vector_store()\n        else:\n            vector_store = FAISS.load_local(\n                folder_path=str(path),\n                embeddings=self.embedding,\n                index_name=self.index_name,\n                allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n            )\n\n        if not vector_store:\n            msg = \"Failed to load the FAISS index.\"\n            raise ValueError(msg)\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n            return docs_to_data(docs)\n        return []\n"
              },
              "embedding": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "index_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Index Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "index_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "index_github"
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "persist_directory": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Persist Directory",
                "dynamic": false,
                "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "persist_directory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "./indices/github"
              },
              "search_query": {
                "_input_type": "QueryInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_query",
                "placeholder": "Enter a query...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "query",
                "value": ""
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "selected_output": "dataframe",
          "showNode": true,
          "type": "FAISS"
        },
        "dragging": false,
        "id": "FAISS-yXWJ4",
        "measured": {
          "height": 455,
          "width": 320
        },
        "position": {
          "x": 694.8729235528831,
          "y": -190.90879988410467
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FAISS-0oYcF",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "vectorstores",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "FAISS Vector Store with search capabilities",
            "display_name": "FAISS",
            "documentation": "",
            "edited": false,
            "field_order": [
              "index_name",
              "persist_directory",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "allow_dangerous_deserialization",
              "embedding",
              "number_of_results"
            ],
            "frozen": false,
            "icon": "FAISS",
            "key": "FAISS",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "group_outputs": false,
                "method": "search_documents",
                "name": "search_results",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "method": "as_dataframe",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 1.3256846433581093e-17,
            "template": {
              "_type": "Component",
              "allow_dangerous_deserialization": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Allow Dangerous Deserialization",
                "dynamic": false,
                "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
                "list": false,
                "list_add_label": "Add More",
                "name": "allow_dangerous_deserialization",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pathlib import Path\n\nfrom langchain_community.vectorstores import FAISS\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import BoolInput, HandleInput, IntInput, StrInput\nfrom langflow.schema.data import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"FAISS Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"langflow_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. \"\n            \"Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    @staticmethod\n    def resolve_path(path: str) -> str:\n        \"\"\"Resolve the path relative to the Langflow root.\n\n        Args:\n            path: The path to resolve\n        Returns:\n            str: The resolved path as a string\n        \"\"\"\n        return str(Path(path).resolve())\n\n    def get_persist_directory(self) -> Path:\n        \"\"\"Returns the resolved persist directory path or the current directory if not set.\"\"\"\n        if self.persist_directory:\n            return Path(self.resolve_path(self.persist_directory))\n        return Path()\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> FAISS:\n        \"\"\"Builds the FAISS object.\"\"\"\n        path = self.get_persist_directory()\n        path.mkdir(parents=True, exist_ok=True)\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n        return faiss\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search for documents in the FAISS vector store.\"\"\"\n        path = self.get_persist_directory()\n        index_path = path / f\"{self.index_name}.faiss\"\n\n        if not index_path.exists():\n            vector_store = self.build_vector_store()\n        else:\n            vector_store = FAISS.load_local(\n                folder_path=str(path),\n                embeddings=self.embedding,\n                index_name=self.index_name,\n                allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n            )\n\n        if not vector_store:\n            msg = \"Failed to load the FAISS index.\"\n            raise ValueError(msg)\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n            return docs_to_data(docs)\n        return []\n"
              },
              "embedding": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "index_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Index Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "index_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "index_pdf"
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "persist_directory": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Persist Directory",
                "dynamic": false,
                "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "persist_directory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "./indices/pdf"
              },
              "search_query": {
                "_input_type": "QueryInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_query",
                "placeholder": "Enter a query...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "query",
                "value": ""
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "selected_output": "dataframe",
          "showNode": true,
          "type": "FAISS"
        },
        "dragging": false,
        "id": "FAISS-0oYcF",
        "measured": {
          "height": 455,
          "width": 320
        },
        "position": {
          "x": 690.7327425033243,
          "y": 296.1735532894652
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-n51Gu",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Combines two input DataFrames into a single Langflow DataFrame object.",
            "display_name": "DataFrame Merger",
            "documentation": "",
            "edited": true,
            "field_order": [
              "dataframe_1",
              "dataframe_2"
            ],
            "frozen": false,
            "icon": "combine",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Combined DataFrame",
                "group_outputs": false,
                "hidden": null,
                "method": "combine_dataframes",
                "name": "combined_df",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\nfrom typing import Any, List\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import DataInput, Output\n# Importamos Data y DataFrame directamente del schema de Langflow\nfrom langflow.schema import Data, DataFrame \n# Ahora usaremos el nombre 'DataFrame' (de Langflow) para el tipo de retorno\n# y 'pd.DataFrame' para el objeto de pandas interno.\n\nclass DataFrameMerger(Component):\n    display_name = \"DataFrame Merger\"\n    description = \"Combines two input DataFrames into a single Langflow DataFrame object.\"\n    icon = \"combine\"\n    name = \"DataFrameMerger\"\n    \n    # ------------------ Inputs ------------------\n    inputs = [\n        DataInput(\n            name=\"dataframe_1\",\n            display_name=\"DataFrame 1 (True Output)\",\n            input_types=[\"DataFrame\"],\n            info=\"The first DataFrame to combine.\",\n            required=False,\n        ),\n        DataInput(\n            name=\"dataframe_2\",\n            display_name=\"DataFrame 2 (True Output)\",\n            input_types=[\"DataFrame\"],\n            info=\"The second DataFrame to combine.\",\n            required=False,\n        ),\n    ]\n\n    # ------------------ Outputs ------------------\n    outputs = [\n        Output(\n            display_name=\"Combined DataFrame\",\n            name=\"combined_df\",\n            # Usamos el tipo de retorno de Langflow 'DataFrame'\n            method=\"combine_dataframes\",\n        ),\n    ]\n\n    # ------------------ Helpers ------------------\n    def _get_dataframe(self, data_input: Any) -> pd.DataFrame:\n        \"\"\"\n        Extracts a pure pandas DataFrame (pd.DataFrame) from the input, \n        handling Langflow wrappers (Data, DataFrame) and None.\n        \"\"\"\n        if data_input is None:\n            return pd.DataFrame()\n        \n        # 1. Si ya es un pandas DataFrame, devuélvelo directamente.\n        if isinstance(data_input, pd.DataFrame):\n            return data_input\n\n        # 2. Si es una lista, intenta extraer el primer DataFrame no vacío.\n        if isinstance(data_input, list):\n            for item in data_input:\n                df = self._get_dataframe(item)\n                if not df.empty:\n                    return df\n            return pd.DataFrame()\n\n        # 3. Si es un wrapper de Langflow (DataFrame o Data), extrae el valor subyacente.\n        if isinstance(data_input, (DataFrame, Data)):\n            # Los wrappers de Langflow suelen tener el pd.DataFrame en 'data' o 'value'\n            value = getattr(data_input, 'data', None) or getattr(data_input, 'value', None)\n            \n            if isinstance(value, pd.DataFrame):\n                return value\n            \n            # Recurrir en caso de que el valor interno sea una lista (para el caso de Data)\n            if isinstance(value, list) and value:\n                df = self._get_dataframe(value[0])\n                if not df.empty:\n                    return df\n\n        # Si no se pudo extraer, devuelve un DataFrame vacío.\n        return pd.DataFrame()\n\n    # ------------------ Output Method ------------------\n    def combine_dataframes(self) -> DataFrame: # ⬅️ Usamos el nombre 'DataFrame' (de Langflow)\n        \"\"\"\n        Combines the two input DataFrames vertically and returns a Langflow DataFrame.\n        \"\"\"\n        # Extrae los DataFrames de Pandas\n        df1 = self._get_dataframe(self.dataframe_1)\n        df2 = self._get_dataframe(self.dataframe_2)\n\n        dataframes_to_concat = []\n        if not df1.empty:\n            df1 = df1.copy()\n            df1.insert(0, \"origin\", \"Github DataFrames\")\n            dataframes_to_concat.append(df1)\n        if not df2.empty:\n            df2 = df2.copy()\n            df2.insert(0, \"origin\", \"PDF DataFrames\")\n            dataframes_to_concat.append(df2)\n\n        if not dataframes_to_concat:\n            self.status = \"No DataFrames provided or both were empty.\"\n            # Devuelve el wrapper de Langflow conteniendo un DF de pandas vacío\n            return DataFrame(data=pd.DataFrame()) \n\n        try:\n            # Combina los DataFrames de Pandas (pd.DataFrame)\n            combined_pd_df = pd.concat(dataframes_to_concat, ignore_index=True)\n            self.status = f\"Successfully combined {len(dataframes_to_concat)} DataFrames. Total rows: {len(combined_pd_df)}\"\n            \n            # CLAVE: Envuelve el pd.DataFrame resultante en el objeto Langflow DataFrame\n            return DataFrame(data=combined_pd_df)\n        \n        except Exception as e:\n            self.status = f\"Error combining DataFrames: {e}\"\n            return DataFrame(data=pd.DataFrame())"
              },
              "dataframe_1": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "DataFrame 1 (True Output)",
                "dynamic": false,
                "info": "The first DataFrame to combine.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "dataframe_1",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "dataframe_2": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "DataFrame 2 (True Output)",
                "dynamic": false,
                "info": "The second DataFrame to combine.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "dataframe_2",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataFrameMerger"
        },
        "dragging": false,
        "id": "CustomComponent-n51Gu",
        "measured": {
          "height": 225,
          "width": 320
        },
        "position": {
          "x": 1452.0914796410736,
          "y": 135.81457226725763
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-N1Dmp",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Format a DataFrame or Data object into text using a template. Enable 'Stringify' to convert input into a readable string instead.",
            "display_name": "Parser",
            "documentation": "",
            "edited": true,
            "field_order": [
              "mode",
              "pattern",
              "input_data",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nfrom typing import Any\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import (BoolInput, HandleInput, MessageTextInput,\r\n                         MultilineInput, Output, TabInput)\r\nfrom langflow.schema import Data, DataFrame\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass ParserComponent(Component):\r\n  name = \"parser\"\r\n  display_name = \"Parser\"\r\n  description = (\r\n    \"Format a DataFrame or Data object into text using a template. \"\r\n    \"Enable 'Stringify' to convert input into a readable string instead.\"\r\n  )\r\n  icon = \"braces\"\r\n  inputs = [\r\n    TabInput(\r\n      name=\"mode\",\r\n      display_name=\"Mode\",\r\n      options=[\"Parser\", \"Stringify\"],\r\n      value=\"Parser\",\r\n      info=\"Convert into raw string instead of using a template.\",\r\n      real_time_refresh=True,\r\n    ),\r\n    MultilineInput(\r\n      name=\"pattern\",\r\n      display_name=\"Template\",\r\n      info=(\r\n        \"Use variables within curly brackets to extract column values for DataFrames \"\r\n        \"or key values for Data.\"\r\n        \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\r\n      ),\r\n      value=\"Text: {text}\", # Example default\r\n      dynamic=True,\r\n      show=True,\r\n      required=True,\r\n    ),\r\n    HandleInput(\r\n      name=\"input_data\",\r\n      display_name=\"Data or DataFrame\",\r\n      input_types=[\"DataFrame\", \"Data\"],\r\n      info=\"Accepts either a DataFrame or a Data object.\",\r\n      required=True,\r\n    ),\r\n    MessageTextInput(\r\n      name=\"sep\",\r\n      display_name=\"Separator\",\r\n      advanced=True,\r\n      value=\"\\n\",\r\n      info=\"String used to separate rows/items.\",\r\n    ),\r\n  ]\r\n\r\n  outputs = [\r\n    Output(\r\n      display_name=\"Parsed Text\",\r\n      name=\"parsed_text\",\r\n      info=\"Formatted text output.\",\r\n      method=\"parse_combined_text\",\r\n    ),\r\n  ]\r\n\r\n  def update_build_config(self, build_config, field_value, field_name=None):\r\n    \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\r\n    if field_name == \"mode\":\r\n      build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\r\n      build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\r\n      if field_value:\r\n        clean_data = BoolInput(\r\n          name=\"clean_data\",\r\n          display_name=\"Clean Data\",\r\n          info=(\r\n            \"Enable to clean the data by removing empty rows and lines \"\r\n            \"in each cell of the DataFrame/ Data object.\"\r\n          ),\r\n          value=True,\r\n          advanced=True,\r\n          required=False,\r\n        )\r\n        build_config[\"clean_data\"] = clean_data.to_dict()\r\n      else:\r\n        build_config.pop(\"clean_data\", None)\r\n    return build_config\r\n\r\n  def _clean_args(self):\r\n    \"\"\"Prepare arguments based on input type.\"\"\"\r\n    input_data = self.input_data\r\n    match input_data:\r\n      case list() if all(isinstance(item, Data) for item in input_data):\r\n        msg = \"List of Data objects is not supported.\"\r\n        raise ValueError(msg)\r\n      case DataFrame():\r\n        return input_data, None\r\n      case Data():\r\n        return None, input_data\r\n      case dict() if \"data\" in input_data:\r\n        try:\r\n          if \"columns\" in input_data: # Likely a DataFrame\r\n            return DataFrame.from_dict(input_data), None\r\n          # Likely a Data object\r\n          return None, Data(**input_data)\r\n        except (TypeError, ValueError, KeyError) as e:\r\n          msg = f\"Invalid structured input provided: {e!s}\"\r\n          raise ValueError(msg) from e\r\n      case _:\r\n        msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\r\n        raise ValueError(msg)\r\n\r\n  def parse_combined_text(self) -> Message:\r\n    \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\r\n    # Early return for stringify option\r\n    if self.mode == \"Stringify\":\r\n      return self.convert_to_string()\r\n    df, data = self._clean_args()\r\n    lines = []\r\n    if df is not None:\r\n      for _, row in df.iterrows():\r\n        formatted_text = self.pattern.format(**row.to_dict())\r\n        lines.append(formatted_text)\r\n    elif data is not None:\r\n      formatted_text = self.pattern.format(**data.data)\r\n      lines.append(formatted_text)\r\n    combined_text = self.sep.join(lines)\r\n    self.status = combined_text\r\n    return Message(text=combined_text)\r\n\r\n  def _safe_convert(self, data: Any) -> str:\r\n    \"\"\"Safely convert input data to string.\"\"\"\r\n    try:\r\n      if isinstance(data, str):\r\n        return data\r\n      if isinstance(data, Message):\r\n        return data.get_text()\r\n      if isinstance(data, Data):\r\n        return json.dumps(data.data)\r\n      if isinstance(data, DataFrame):\r\n        if hasattr(self, \"clean_data\") and self.clean_data:\r\n          # Remove empty rows\r\n          data = data.dropna(how=\"all\")\r\n          # Remove empty lines in each cell\r\n          data = data.replace(r\"^\\s*$\", \"\", regex=True)\r\n          # Replace multiple newlines with a single newline\r\n          data = data.replace(r\"\\n+\", \"\\n\", regex=True)\r\n        return data.to_markdown(index=False)\r\n      return str(data)\r\n    except (ValueError, TypeError, AttributeError) as e:\r\n      msg = f\"Error converting data: {e!s}\"\r\n      raise ValueError(msg) from e\r\n\r\n  def convert_to_string(self) -> Message:\r\n    \"\"\"Convert input data to string with proper error handling.\"\"\"\r\n    result = \"\"\r\n    if isinstance(self.input_data, list):\r\n      result = \"\\n\".join([self._safe_convert(item) for item in self.input_data])\r\n    else:\r\n      result = self._safe_convert(self.input_data)\r\n    self.log(f\"Converted to string with length: {len(result)}\")"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Source: {source}, Origin: {origin}, Text: {text}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "parser"
        },
        "dragging": false,
        "id": "CustomComponent-N1Dmp",
        "measured": {
          "height": 359,
          "width": 320
        },
        "position": {
          "x": 1795.5011159541907,
          "y": 59.93252606583522
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-4TVDv",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "openai",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIModel",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000001,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_CHAT_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        logger.debug(f\"Executing request with model: {self.model_name}\")\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n        }\n\n        # TODO: Revisit if/once parameters are supported for reasoning models\n        unsupported_params_for_reasoning_models = [\"temperature\", \"seed\"]\n\n        if self.model_name not in OPENAI_REASONING_MODEL_NAMES:\n            parameters[\"temperature\"] = self.temperature if self.temperature is not None else 0.1\n            parameters[\"seed\"] = self.seed\n        else:\n            params_str = \", \".join(unsupported_params_for_reasoning_models)\n            logger.debug(f\"{self.model_name} is a reasoning model, {params_str} are not configurable. Ignoring.\")\n\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n            # Hide system_message for o1 models - currently unsupported\n            if field_value.startswith(\"o1\") and \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_CHAT_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n            if \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1",
                  "o1-mini",
                  "o1-pro",
                  "o3-mini",
                  "o3",
                  "o3-pro",
                  "o4-mini",
                  "o4-mini-high"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-4TVDv",
        "measured": {
          "height": 537,
          "width": 320
        },
        "position": {
          "x": 2519.4767194947462,
          "y": 65.18812815478753
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-7vMII",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "question"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "question": {
                "advanced": false,
                "display_name": "question",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a high-performance assistant specialized in context analysis. \nYour sole task is to **answer the question** based strictly on the provided context (Structured Context and Web Context).\n\n**PRIORITIZATION RULE (CRITICAL):**\n1.  **Prioritize Sources:** When synthesizing the answer, you **must prioritize** information found in **PDF** and **GitHub** content.\n2.  **Web as Supplemental:** Use the **Web** context only to fill gaps, provide supporting details, or complete the answer if the **PDF** and **GitHub** sources are insufficient or absent.\n3.  **LLM as Fallback:** Only use **LLM prior knowledge** if the information is entirely missing or insufficient across all provided contexts (PDF, GitHub, and Web).\n\nYou must **strictly adhere** to the following output format. **DO NOT** include any other explanation or text outside of this format.\n\n1. Always begin with the literal header **Answer:**. \n2. Provide the answer to the question immediately after the **Answer:** header. The response must be concise, complete, and high-quality. \n3. After the answer, skip one line and add the literal header **Source Traceability:**. \n4. Under **Source Traceability:**, list the sources you used. You may only use the source types: **PDF**, **GitHub**, **Web**, or **LLM prior knowledge**. \n5. You must assign a percentage contribution, summing to a total of 100% across all used sources. The percentage assigned must reflect the **prioritization rule** (PDF/GitHub should receive higher percentages when used). \n6. Format each source as a Markdown list item (-) followed by the type and the percentage: - [Type]: [Percentage]%. \n\n7. **Suggested Questions Policy:** \n    7.1. Only include a **Suggested Questions** section if BOTH of the following conditions are met: \n        - The original question was appropriate for a RAG system (i.e., it seeks factual, contextual, or document-based information). \n        - The question is directly related to information from **PDFs or GitHub repositories**. \n    7.2. In this section, list 1–3 related or alternative questions that could yield better or more specific results. \n    7.3. If the question does not meet these criteria, **omit this section entirely**.\n\n8. **Critical Rule for Missing Information:** \n    8.1. If no relevant information is found in the provided context, or you cannot confidently answer, you MUST still fill the **Answer** section using your prior knowledge. \n    8.2. Leaving the **Answer** section empty is strictly forbidden. \n\n**STRICT REQUIRED OUTPUT FORMAT:**\n\n**Answer:** [Your concise answer based on the context. If none, respond using your prior knowledge.]\n\n**Source Traceability:** \n- PDF: [Percentage]% \n- GitHub: [Percentage]% \n- Web: [Percentage]% \n- LLM prior knowledge: [Percentage]%\n\n**Suggested Questions:** \n- [Question 1] \n- [Question 2] \n- [Question 3] \n\n(Only include this section if the question was appropriate for RAG and related to PDFs or GitHub repositories.)\n\nGiven the context, answer the question as best as possible.\n\nQuestion: {question} \nAnswer:"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "prompt",
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-7vMII",
        "measured": {
          "height": 365,
          "width": 320
        },
        "position": {
          "x": 2154.5175500478367,
          "y": 229.26198076829473
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LocalHuggingFaceEmbeddings-O3z78",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Usa modelos HuggingFace locales para generar embeddings.",
            "display_name": "Local HuggingFace Embeddings",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "edited": true,
            "field_order": [
              "model_name"
            ],
            "frozen": false,
            "icon": "brain-circuit",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "group_outputs": false,
                "hidden": null,
                "method": "build_output",
                "name": "embeddings",
                "options": null,
                "required_inputs": null,
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.schema.embeddings import Embeddings\n\n\nclass CustomComponent(Component):\n    display_name = \"Local HuggingFace Embeddings\"\n    description = \"Usa modelos HuggingFace locales para generar embeddings.\"\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"brain-circuit\"\n    name = \"LocalHuggingFaceEmbeddings\"\n\n    # -------- Inputs --------\n    inputs = [\n        MessageTextInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            info=\"Nombre del modelo HuggingFace a usar\",\n            value=\"BAAI/bge-small-en-v1.5\",  # Valor por defecto\n            tool_mode=True,\n        ),\n    ]\n\n    # -------- Outputs --------\n    outputs = [\n        Output(\n            display_name=\"Embeddings\",\n            name=\"embeddings\",\n            method=\"build_output\",\n        ),\n    ]\n\n    # -------- Lógica principal --------\n    def build_output(self) -> Embeddings:\n        model_name = self.model_name\n        embeddings = HuggingFaceEmbeddings(\n            model_name=model_name,\n            encode_kwargs={\"normalize_embeddings\": True},\n        )\n        self.status = f\"Modelo cargado: {model_name}\"\n        return embeddings"
              },
              "model_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Model Name",
                "dynamic": false,
                "info": "Nombre del modelo HuggingFace a usar",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "model_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "BAAI/bge-small-en-v1.5"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LocalHuggingFaceEmbeddings"
        },
        "dragging": false,
        "id": "LocalHuggingFaceEmbeddings-O3z78",
        "measured": {
          "height": 219,
          "width": 320
        },
        "position": {
          "x": 297.7873986998073,
          "y": 321.56644888441724
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-pE1Im",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts and formats the AI Overview and search results from the JigsawStack AI Search component into a single, structured text.",
            "display_name": "JigsawStack AI Search Parser",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_data",
              "separator"
            ],
            "frozen": false,
            "icon": "puzzle-piece",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Formatted Search Context",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_search_results",
                "name": "formatted_context_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\r\nfrom typing import Any, List, Dict\r\n\r\nfrom langflow.custom.custom_component.component import Component\r\nfrom langflow.io import (\r\n    DataInput,\r\n    Output,\r\n    MessageTextInput,\r\n)\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message\r\n\r\nclass JigsawStackAIParserComponent(Component):\r\n    display_name = \"JigsawStack AI Search Parser\"\r\n    description = \"Extracts and formats the AI Overview and search results from the JigsawStack AI Search component into a single, structured text.\"\r\n    icon = \"puzzle-piece\"\r\n    name = \"JigsawStackAIParser\"\r\n\r\n    # ------------------ Inputs ------------------\r\n    inputs = [\r\n        DataInput(\r\n            name=\"input_data\",\r\n            display_name=\"Search Results Data\",\r\n            input_types=[\"Data\"],\r\n            info=\"The output Data object from the JigsawStack AI Search component.\",\r\n            required=True,\r\n            is_list=False, # Esperamos UN solo objeto Data\r\n        ),\r\n        MessageTextInput(\r\n            name=\"separator\",\r\n            display_name=\"Result Separator\",\r\n            advanced=True,\r\n            value=\"\\n---\\n\",\r\n            info=\"String used to separate the content of each individual search result block.\",\r\n        ),\r\n    ]\r\n\r\n    # ------------------ Outputs ------------------\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Formatted Search Context\",\r\n            name=\"formatted_context_output\",\r\n            method=\"parse_search_results\",\r\n        ),\r\n    ]\r\n\r\n    # ------------------ Helpers ------------------\r\n    def _format_result(self, result: Dict[str, Any], index: int) -> str:\r\n        \"\"\"Formatea un resultado individual de la búsqueda.\"\"\"\r\n        title = result.get(\"title\", \"No Title\")\r\n        url = result.get(\"url\", \"No URL\")\r\n        \r\n        # Limitamos los snippets para mantener la coherencia y evitar texto excesivo\r\n        snippets = \"\\n\".join([f\"- {s}\" for s in result.get(\"snippets\", [])[:3]]) # Limitamos a 3 snippets por resultado\r\n        \r\n        return (\r\n            f\"Result {index + 1}: {title}\\n\"\r\n            f\"Source: {url}\\n\"\r\n            f\"Relevant Snippets:\\n\"\r\n            f\"{snippets}\\n\"\r\n        )\r\n        \r\n    def _extract_search_data(self, input_item: Any) -> Dict[str, Any]:\r\n        \"\"\"Extrae el diccionario de resultados del objeto Data de Langflow.\"\"\"\r\n        if isinstance(input_item, Data):\r\n            # Asumimos que el valor del objeto Data es el diccionario de la API\r\n            return input_item.data if isinstance(input_item.data, dict) else {}\r\n        if isinstance(input_item, dict):\r\n            return input_item\r\n        return {}\r\n\r\n\r\n    # ------------------ Output Method ------------------\r\n    def parse_search_results(self) -> Message:\r\n        \"\"\"\r\n        Extrae el AI Overview y los resultados de la búsqueda, los formatea\r\n        y los combina en un único mensaje estructurado.\r\n        \"\"\"\r\n        \r\n        # 1. Extraer el diccionario de resultados de la API\r\n        search_data = self._extract_search_data(self.input_data)\r\n        \r\n        if not search_data:\r\n            self.status = \"Error: Input data is empty or not in the expected format (JigsawStack Data).\"\r\n            return Message(text=\"\")\r\n\r\n        # 2. Extraer AI Overview y Results\r\n        ai_overview = search_data.get(\"ai_overview\", \"\")\r\n        # NOTA: La lista 'results' ya viene limitada desde el nodo JigsawStackAIWebSearchComponent.\r\n        results = search_data.get(\"results\", [])\r\n        separator = self.separator \r\n\r\n        # 3. Formatear los resultados individuales (links/snippets)\r\n        formatted_results = []\r\n        for i, result in enumerate(results):\r\n            formatted_results.append(self._format_result(result, i))\r\n\r\n        # 4. Combinar la lista de resultados formateados en un bloque\r\n        supporting_results_block = separator.join(formatted_results)\r\n\r\n        # 5. Construir la lista de contenido final\r\n        combined_text_parts = []\r\n\r\n        if ai_overview:\r\n            combined_text_parts.append(\"## AI Overview\\n\" + ai_overview)\r\n            \r\n        if supporting_results_block:\r\n            # Añadimos un separador solo si hay AI Overview y resultados\r\n            if ai_overview:\r\n                 combined_text_parts.append(separator)\r\n\r\n            combined_text_parts.append(\"## Supporting Search Results\")\r\n            combined_text_parts.append(supporting_results_block)\r\n\r\n        # 6. Unir todas las partes principales\r\n        final_text = \"\\n\".join(combined_text_parts)\r\n        \r\n        self.status = f\"Parsed {len(results)} search results and AI Overview. Total length: {len(final_text)}.\"\r\n        \r\n        # 7. Devolver como un objeto Message de Langflow\r\n        return Message(text=final_text)"
              },
              "input_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Search Results Data",
                "dynamic": false,
                "info": "The output Data object from the JigsawStack AI Search component.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "separator": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Result Separator",
                "dynamic": false,
                "info": "String used to separate the content of each individual search result block.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n---\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "JigsawStackAIParser"
        },
        "dragging": false,
        "id": "CustomComponent-pE1Im",
        "measured": {
          "height": 197,
          "width": 320
        },
        "position": {
          "x": 1474.9294993315252,
          "y": -408.82247954686227
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-HweCC",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Combines two separate text inputs (e.g., Structured Data and Web Search) into one final context string.",
            "display_name": "Context Text Merger",
            "documentation": "",
            "edited": true,
            "field_order": [
              "web_search_context",
              "structured_data_text"
            ],
            "frozen": false,
            "icon": "code-pull-request-draft",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Final Unified Context",
                "group_outputs": false,
                "hidden": null,
                "method": "merge_context",
                "name": "unified_context",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import (\n    MessageTextInput,\n    Output,\n    MessageInput,\n)\nfrom langflow.schema.message import Message\nfrom typing import Any\n\nclass ContextTextMerger(Component):\n    display_name = \"Context Text Merger\"\n    description = \"Combines two separate text inputs (e.g., Structured Data and Web Search) into one final context string.\"\n    icon = \"code-pull-request-draft\"\n    name = \"ContextTextMerger\"\n\n    # ------------------ Inputs ------------------\n    inputs = [\n        MessageInput(\n            name=\"web_search_context\",\n            display_name=\"Web Search Context (from Combine Documents)\",\n            info=\"The combined text from the Web Search/Combine Documents component.\",\n            required=False,\n        ),\n        MessageInput(\n            name=\"structured_data_text\",\n            display_name=\"Structured Data Text (from Parser)\",\n            info=\"The formatted text from the DataFrame/Parser component.\",\n            required=True,\n        ),\n    ]\n\n    # ------------------ Outputs ------------------\n    outputs = [\n        Output(\n            display_name=\"Final Unified Context\",\n            name=\"unified_context\",\n            method=\"merge_context\",\n        ),\n    ]\n\n    # ------------------ Helper ------------------\n    def _to_str(self, v: Any) -> str:\n        \"\"\"Extrae la cadena de texto de un objeto Message o valor simple.\"\"\"\n        if v is None:\n            return \"\"\n        if isinstance(v, Message):\n            return v.text if v.text else \"\"\n        return str(v)\n\n    # ------------------ Output Method ------------------\n    def merge_context(self) -> Message:\n        \"\"\"Combina los dos contextos con encabezados claros.\"\"\"\n        \n        # 1. Extraer el texto de las entradas\n        data_text = self._to_str(self.structured_data_text).strip()\n        web_text = self._to_str(self.web_search_context).strip()\n        \n        unified_context_parts = []\n        \n        # 2. Formatear y añadir el contexto estructurado\n        if data_text:\n            unified_context_parts.append(\n                \"--- INICIO DATOS ESTRUCTURADOS ---\\n\"\n                f\"{data_text}\\n\"\n                \"--- FIN DATOS ESTRUCTURADOS ---\"\n            )\n\n        # 3. Formatear y añadir el contexto de búsqueda web\n        if web_text:\n            # Añadir un separador si ya hay datos estructurados\n            if unified_context_parts:\n                 unified_context_parts.append(\"\\n\\n\") \n                 \n            unified_context_parts.append(\n                \"--- INICIO CONTEXTO WEB ---\\n\"\n                f\"{web_text}\\n\"\n                \"--- FIN CONTEXTO WEB ---\"\n            )\n\n        # 4. Unir todas las partes\n        final_context = \"\".join(unified_context_parts)\n        \n        if not final_context:\n            self.status = \"No context was provided to merge.\"\n            return Message(text=\"\")\n\n        self.status = f\"Successfully merged two contexts into a single string of length {len(final_context)}.\"\n        \n        # 5. Devolver como un único objeto Message\n        return Message(text=final_context)\n"
              },
              "structured_data_text": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Structured Data Text (from Parser)",
                "dynamic": false,
                "info": "The formatted text from the DataFrame/Parser component.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "structured_data_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "web_search_context": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Web Search Context (from Combine Documents)",
                "dynamic": false,
                "info": "The combined text from the Web Search/Combine Documents component.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "web_search_context",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ContextTextMerger"
        },
        "dragging": false,
        "id": "CustomComponent-HweCC",
        "measured": {
          "height": 317,
          "width": 320
        },
        "position": {
          "x": 2149.3212150657687,
          "y": -138.623185598474
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-RZ4gB",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes input message and/or DataFrame based on a conditional check.",
            "display_name": "If-Else with DataFrame",
            "documentation": "https://docs.langflow.org/components-logic#conditional-router-if-else-component",
            "edited": true,
            "field_order": [
              "input_text",
              "operator",
              "match_text",
              "case_sensitive",
              "true_case_message",
              "false_case_message",
              "max_iterations",
              "default_route",
              "input_dataframe"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True Message",
                "group_outputs": true,
                "hidden": null,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False Message",
                "group_outputs": true,
                "hidden": null,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame (if True)",
                "group_outputs": false,
                "hidden": null,
                "method": "df_response",
                "name": "df_result",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\nfrom typing import Any, List\nimport pandas as pd\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import (\n  BoolInput,\n  DropdownInput,\n  IntInput,\n  MessageInput,\n  MessageTextInput,\n  Output,\n  DataInput,\n)\nfrom langflow.schema.message import Message\nfrom langflow.schema.data import Data\nclass ConditionalRouterComponent(Component):\n  display_name = \"If-Else with DataFrame\"\n  description = \"Routes input message and/or DataFrame based on a conditional check.\"\n  documentation: str = \"https://docs.langflow.org/components-logic#conditional-router-if-else-component\"\n  icon = \"split\"\n  name = \"ConditionalRouter\"\n  id = \"ConditionalRouter\"\n  def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.__iteration_updated = False\n  inputs = [\n    MessageTextInput(\n      name=\"input_text\",\n      display_name=\"Text Input\",\n      info=\"The primary text input for the operation.\",\n      required=True,\n    ),\n    DropdownInput(\n      name=\"operator\",\n      display_name=\"Operator\",\n      options=[\n        \"equals\",\n        \"not equals\",\n        \"contains\",\n        \"starts with\",\n        \"ends with\",\n        \"regex\",\n        \"less than\",\n        \"less than or equal\",\n        \"greater than\",\n        \"greater than or equal\",\n      ],\n      info=\"The operator to apply for comparing the texts.\",\n      value=\"equals\",\n      real_time_refresh=True,\n    ),\n    MessageTextInput(\n      name=\"match_text\",\n      display_name=\"Match Text\",\n      info=\"The text input to compare against.\",\n      required=True,\n    ),\n    BoolInput(\n      name=\"case_sensitive\",\n      display_name=\"Case Sensitive\",\n      info=\"If true, the comparison will be case sensitive.\",\n      value=True,\n      advanced=True,\n    ),\n    MessageInput(\n      name=\"true_case_message\",\n      display_name=\"Case True\",\n      info=\"The message to pass if the condition is True.\",\n      advanced=True,\n    ),\n    MessageInput(\n      name=\"false_case_message\",\n      display_name=\"Case False\",\n      info=\"The message to pass if the condition is False.\",\n      advanced=True,\n    ),\n    IntInput(\n      name=\"max_iterations\",\n      display_name=\"Max Iterations\",\n      info=\"The maximum number of iterations for the conditional router.\",\n      value=10,\n      advanced=True,\n    ),\n    DropdownInput(\n      name=\"default_route\",\n      display_name=\"Default Route\",\n      options=[\"true_result\", \"false_result\"],\n      info=\"The default route to take when max iterations are reached.\",\n      value=\"false_result\",\n      advanced=True,\n    ),\n    DataInput(\n      name=\"input_dataframe\",\n      display_name=\"Input DataFrame\",\n      input_types=[\"DataFrame\"],\n      required=False,\n    ),\n  ]\n  outputs = [\n    Output(display_name=\"True Message\", name=\"true_result\", method=\"true_response\", group_outputs=True),\n    Output(display_name=\"False Message\", name=\"false_result\", method=\"false_response\", group_outputs=True),\n    Output(display_name=\"DataFrame (if True)\", name=\"df_result\", method=\"df_response\"),\n  ]\n  def _pre_run_setup(self):\n    self.__iteration_updated = False\n  # ---------- Helpers ----------\n  def _to_str(self, v: Any) -> str:\n    \"\"\"Intenta extraer texto de distintos tipos de input (Message, Data, plain).\"\"\"\n    if v is None:\n      return \"\"\n    # Message-like (has content)\n    if hasattr(v, \"content\"):\n      return str(v.content or \"\")\n    # Data-like (has value)\n    if hasattr(v, \"value\") and not isinstance(v, str):\n      # si el .value es str o nmero lo devolvemos\n      val = v.value\n      if isinstance(val, str):\n        return val\n      # si es dict con page_content\n      if isinstance(val, dict) and \"page_content\" in val:\n        return str(val.get(\"page_content\", \"\"))\n      # si es objeto con attr page_content\n      if hasattr(val, \"page_content\"):\n        return str(getattr(val, \"page_content\", \"\"))\n      # fallback\n      return str(val)\n    # plain string / numeric\n    return str(v)\n  def evaluate_condition(self, input_text: Any, match_text: Any, operator: str, *, case_sensitive: bool) -> bool:\n    # Normalizamos a strings\n    input_s = self._to_str(input_text)\n    match_s = self._to_str(match_text)\n    if not case_sensitive and operator != \"regex\":\n      input_s = input_s.lower()\n      match_s = match_s.lower()\n    try:\n      if operator == \"equals\":\n        return input_s == match_s\n      if operator == \"not equals\":\n        return input_s != match_s\n      if operator == \"contains\":\n        return match_s in input_s\n      if operator == \"starts with\":\n        return input_s.startswith(match_s)\n      if operator == \"ends with\":\n        return input_s.endswith(match_s)\n      if operator == \"regex\":\n        try:\n          return bool(re.search(match_s, input_s))\n        except re.error:\n          return False\n      if operator in [\"less than\", \"less than or equal\", \"greater than\", \"greater than or equal\"]:\n        input_num = float(input_s)\n        match_num = float(match_s)\n        if operator == \"less than\":\n          return input_num < match_num\n        if operator == \"less than or equal\":\n          return input_num <= match_num\n        if operator == \"greater than\":\n          return input_num > match_num\n        if operator == \"greater than or equal\":\n          return input_num >= match_num\n    except (ValueError, TypeError):\n      return False\n    return False\n  def iterate_and_stop_once(self, route_to_stop: str):\n    if not self.__iteration_updated:\n      self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n      self.__iteration_updated = True\n      if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n        route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n      self.stop(route_to_stop)\n  def true_response(self) -> Message:\n    result = self.evaluate_condition(\n      self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n    )\n    if result:\n      self.status = self.true_case_message\n      self.iterate_and_stop_once(\"false_result\")\n      return self.true_case_message\n    self.iterate_and_stop_once(\"true_result\")\n    return Message(content=\"\")\n  def false_response(self) -> Message:\n    result = self.evaluate_condition(\n      self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n    )\n    if not result:\n      self.status = self.false_case_message\n      self.iterate_and_stop_once(\"true_result\")\n      return self.false_case_message\n    self.iterate_and_stop_once(\"false_result\")\n    return Message(content=\"\")\n  # ---------- Conversin robusta ----------\n  def _convert_raw_to_dataframe(self, raw: Any) -> pd.DataFrame:\n    \"\"\"\n    Convierte distintos formatos (pd.DataFrame, list[Data], list[dict], Data, dict, str, Document) a pandas.DataFrame\n    con al menos la columna 'text'.\n    \"\"\"\n    # 1) pd.DataFrame -> passthrough\n    if isinstance(raw, pd.DataFrame):\n      df = raw.copy()\n    # 2) Data (wrapper) -> unwrap y recursar\n    elif isinstance(raw, Data):\n      return self._convert_raw_to_dataframe(raw.value)\n    # 3) lista\n    elif isinstance(raw, list):\n      if len(raw) == 0:\n        return pd.DataFrame()\n      rows = []\n      for item in raw:\n        # si es Data, extraemos .value\n        if isinstance(item, Data):\n          val = item.value\n        else:\n          val = item\n        # si es dict con page_content / metadata (salida tpica de docs_to_data)\n        if isinstance(val, dict):\n          if \"page_content\" in val:\n            # preferimos colocar page_content en 'text'\n            row = {\"text\": val.get(\"page_content\", \"\")}\n            # si hay metadata, lo incorporamos (opcional)\n            meta = val.get(\"metadata\")\n            if isinstance(meta, dict):\n              # anexamos las keys de metadata como columnas\n              row.update(meta)\n            else:\n              # si metadata no es dict, lo guardamos como metadata_text\n              row[\"metadata\"] = str(meta)\n            rows.append(row)\n          else:\n            # dict arbitrario -> uso directo de sus campos\n            rows.append(val)\n        # si es objeto tipo Document (atributos .page_content, .metadata)\n        elif hasattr(val, \"page_content\"):\n          meta = getattr(val, \"metadata\", {})\n          row = {\"text\": getattr(val, \"page_content\", \"\")}\n          if isinstance(meta, dict):\n            row.update(meta)\n          rows.append(row)\n        # string / number -> texto simple\n        elif isinstance(val, (str, int, float)):\n          rows.append({\"text\": str(val)})\n        # cualquier otro -> representacin string\n        else:\n          rows.append({\"text\": str(val)})\n      df = pd.DataFrame(rows) if rows else pd.DataFrame()\n    # 4) dict individual\n    elif isinstance(raw, dict):\n      if \"page_content\" in raw:\n        row = {\"text\": raw.get(\"page_content\", \"\")}\n        meta = raw.get(\"metadata\")\n        if isinstance(meta, dict):\n          row.update(meta)\n        else:\n          row[\"metadata\"] = str(meta)\n        df = pd.DataFrame([row])\n      else:\n        df = pd.DataFrame([raw])\n    # 5) string / numeric -> 1-row DF\n    elif isinstance(raw, (str, int, float)):\n      df = pd.DataFrame([{\"text\": str(raw)}])\n    # 6) fallback: intentar str()\n    else:\n      df = pd.DataFrame([{\"text\": str(raw)}])\n    # Aseguramos la columna 'text'\n    if \"text\" not in df.columns:\n      if \"page_content\" in df.columns:\n        df[\"text\"] = df[\"page_content\"]\n      else:\n        # si existe alguna columna que parezca contener texto, intentar usarla\n        possible_text_cols = [c for c in df.columns if df[c].dtype == object]\n        if possible_text_cols:\n          df[\"text\"] = df[possible_text_cols[0]].astype(str)\n        else:\n          df[\"text\"] = \"\"\n    return df\n  # ---------- Output method ----------\n  def df_response(self) -> pd.DataFrame:\n    \"\"\"\n    Devuelve exactamente el input_dataframe si la condicin es True.\n    Si la condicin es False devuelve un DataFrame vaco.\n    \"\"\"\n    try:\n      result = self.evaluate_condition(\n        self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n      )\n    except Exception as e:\n      self.status = f\"Error evaluando condicin: {e}\"\n      return pd.DataFrame()\n    if not result:\n      self.status = \"Condicin evaluada como False -> devolviendo DataFrame vaco.\"\n      return pd.DataFrame()\n    # Si es True, devolvemos exactamente el input recibido\n    if hasattr(self, \"input_dataframe\"):\n      raw = self.input_dataframe\n      # Si es wrapper Data, tomamos .value\n      if hasattr(raw, \"value\"):\n        return raw.value\n      return raw\n    # fallback\n    return pd.DataFrame()"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "false_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case False",
                "dynamic": false,
                "info": "The message to pass if the condition is False.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "false_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_dataframe": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Input DataFrame",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_dataframe",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "PDF_INGESTED"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex",
                  "less than",
                  "less than or equal",
                  "greater than",
                  "greater than or equal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              },
              "true_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case True",
                "dynamic": false,
                "info": "The message to pass if the condition is True.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "true_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-RZ4gB",
        "measured": {
          "height": 515,
          "width": 320
        },
        "position": {
          "x": 1088.426066108659,
          "y": 357.1128248900406
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-92JKj",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes input message and/or DataFrame based on a conditional check.",
            "display_name": "If-Else with DataFrame",
            "documentation": "https://docs.langflow.org/components-logic#conditional-router-if-else-component",
            "edited": true,
            "field_order": [
              "input_text",
              "operator",
              "match_text",
              "case_sensitive",
              "true_case_message",
              "false_case_message",
              "max_iterations",
              "default_route",
              "input_dataframe"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True Message",
                "group_outputs": true,
                "hidden": null,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False Message",
                "group_outputs": true,
                "hidden": null,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame (if True)",
                "group_outputs": false,
                "hidden": null,
                "method": "df_response",
                "name": "df_result",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\nfrom typing import Any, List\nimport pandas as pd\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import (\n  BoolInput,\n  DropdownInput,\n  IntInput,\n  MessageInput,\n  MessageTextInput,\n  Output,\n  DataInput,\n)\nfrom langflow.schema.message import Message\nfrom langflow.schema.data import Data\nclass ConditionalRouterComponent(Component):\n  display_name = \"If-Else with DataFrame\"\n  description = \"Routes input message and/or DataFrame based on a conditional check.\"\n  documentation: str = \"https://docs.langflow.org/components-logic#conditional-router-if-else-component\"\n  icon = \"split\"\n  name = \"ConditionalRouter\"\n  id = \"ConditionalRouter\"\n  def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.__iteration_updated = False\n  inputs = [\n    MessageTextInput(\n      name=\"input_text\",\n      display_name=\"Text Input\",\n      info=\"The primary text input for the operation.\",\n      required=True,\n    ),\n    DropdownInput(\n      name=\"operator\",\n      display_name=\"Operator\",\n      options=[\n        \"equals\",\n        \"not equals\",\n        \"contains\",\n        \"starts with\",\n        \"ends with\",\n        \"regex\",\n        \"less than\",\n        \"less than or equal\",\n        \"greater than\",\n        \"greater than or equal\",\n      ],\n      info=\"The operator to apply for comparing the texts.\",\n      value=\"equals\",\n      real_time_refresh=True,\n    ),\n    MessageTextInput(\n      name=\"match_text\",\n      display_name=\"Match Text\",\n      info=\"The text input to compare against.\",\n      required=True,\n    ),\n    BoolInput(\n      name=\"case_sensitive\",\n      display_name=\"Case Sensitive\",\n      info=\"If true, the comparison will be case sensitive.\",\n      value=True,\n      advanced=True,\n    ),\n    MessageInput(\n      name=\"true_case_message\",\n      display_name=\"Case True\",\n      info=\"The message to pass if the condition is True.\",\n      advanced=True,\n    ),\n    MessageInput(\n      name=\"false_case_message\",\n      display_name=\"Case False\",\n      info=\"The message to pass if the condition is False.\",\n      advanced=True,\n    ),\n    IntInput(\n      name=\"max_iterations\",\n      display_name=\"Max Iterations\",\n      info=\"The maximum number of iterations for the conditional router.\",\n      value=10,\n      advanced=True,\n    ),\n    DropdownInput(\n      name=\"default_route\",\n      display_name=\"Default Route\",\n      options=[\"true_result\", \"false_result\"],\n      info=\"The default route to take when max iterations are reached.\",\n      value=\"false_result\",\n      advanced=True,\n    ),\n    DataInput(\n      name=\"input_dataframe\",\n      display_name=\"Input DataFrame\",\n      input_types=[\"DataFrame\"],\n      required=False,\n    ),\n  ]\n  outputs = [\n    Output(display_name=\"True Message\", name=\"true_result\", method=\"true_response\", group_outputs=True),\n    Output(display_name=\"False Message\", name=\"false_result\", method=\"false_response\", group_outputs=True),\n    Output(display_name=\"DataFrame (if True)\", name=\"df_result\", method=\"df_response\"),\n  ]\n  def _pre_run_setup(self):\n    self.__iteration_updated = False\n  # ---------- Helpers ----------\n  def _to_str(self, v: Any) -> str:\n    \"\"\"Intenta extraer texto de distintos tipos de input (Message, Data, plain).\"\"\"\n    if v is None:\n      return \"\"\n    # Message-like (has content)\n    if hasattr(v, \"content\"):\n      return str(v.content or \"\")\n    # Data-like (has value)\n    if hasattr(v, \"value\") and not isinstance(v, str):\n      # si el .value es str o nmero lo devolvemos\n      val = v.value\n      if isinstance(val, str):\n        return val\n      # si es dict con page_content\n      if isinstance(val, dict) and \"page_content\" in val:\n        return str(val.get(\"page_content\", \"\"))\n      # si es objeto con attr page_content\n      if hasattr(val, \"page_content\"):\n        return str(getattr(val, \"page_content\", \"\"))\n      # fallback\n      return str(val)\n    # plain string / numeric\n    return str(v)\n  def evaluate_condition(self, input_text: Any, match_text: Any, operator: str, *, case_sensitive: bool) -> bool:\n    # Normalizamos a strings\n    input_s = self._to_str(input_text)\n    match_s = self._to_str(match_text)\n    if not case_sensitive and operator != \"regex\":\n      input_s = input_s.lower()\n      match_s = match_s.lower()\n    try:\n      if operator == \"equals\":\n        return input_s == match_s\n      if operator == \"not equals\":\n        return input_s != match_s\n      if operator == \"contains\":\n        return match_s in input_s\n      if operator == \"starts with\":\n        return input_s.startswith(match_s)\n      if operator == \"ends with\":\n        return input_s.endswith(match_s)\n      if operator == \"regex\":\n        try:\n          return bool(re.search(match_s, input_s))\n        except re.error:\n          return False\n      if operator in [\"less than\", \"less than or equal\", \"greater than\", \"greater than or equal\"]:\n        input_num = float(input_s)\n        match_num = float(match_s)\n        if operator == \"less than\":\n          return input_num < match_num\n        if operator == \"less than or equal\":\n          return input_num <= match_num\n        if operator == \"greater than\":\n          return input_num > match_num\n        if operator == \"greater than or equal\":\n          return input_num >= match_num\n    except (ValueError, TypeError):\n      return False\n    return False\n  def iterate_and_stop_once(self, route_to_stop: str):\n    if not self.__iteration_updated:\n      self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n      self.__iteration_updated = True\n      if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n        route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n      self.stop(route_to_stop)\n  def true_response(self) -> Message:\n    result = self.evaluate_condition(\n      self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n    )\n    if result:\n      self.status = self.true_case_message\n      self.iterate_and_stop_once(\"false_result\")\n      return self.true_case_message\n    self.iterate_and_stop_once(\"true_result\")\n    return Message(content=\"\")\n  def false_response(self) -> Message:\n    result = self.evaluate_condition(\n      self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n    )\n    if not result:\n      self.status = self.false_case_message\n      self.iterate_and_stop_once(\"true_result\")\n      return self.false_case_message\n    self.iterate_and_stop_once(\"false_result\")\n    return Message(content=\"\")\n  # ---------- Conversin robusta ----------\n  def _convert_raw_to_dataframe(self, raw: Any) -> pd.DataFrame:\n    \"\"\"\n    Convierte distintos formatos (pd.DataFrame, list[Data], list[dict], Data, dict, str, Document) a pandas.DataFrame\n    con al menos la columna 'text'.\n    \"\"\"\n    # 1) pd.DataFrame -> passthrough\n    if isinstance(raw, pd.DataFrame):\n      df = raw.copy()\n    # 2) Data (wrapper) -> unwrap y recursar\n    elif isinstance(raw, Data):\n      return self._convert_raw_to_dataframe(raw.value)\n    # 3) lista\n    elif isinstance(raw, list):\n      if len(raw) == 0:\n        return pd.DataFrame()\n      rows = []\n      for item in raw:\n        # si es Data, extraemos .value\n        if isinstance(item, Data):\n          val = item.value\n        else:\n          val = item\n        # si es dict con page_content / metadata (salida tpica de docs_to_data)\n        if isinstance(val, dict):\n          if \"page_content\" in val:\n            # preferimos colocar page_content en 'text'\n            row = {\"text\": val.get(\"page_content\", \"\")}\n            # si hay metadata, lo incorporamos (opcional)\n            meta = val.get(\"metadata\")\n            if isinstance(meta, dict):\n              # anexamos las keys de metadata como columnas\n              row.update(meta)\n            else:\n              # si metadata no es dict, lo guardamos como metadata_text\n              row[\"metadata\"] = str(meta)\n            rows.append(row)\n          else:\n            # dict arbitrario -> uso directo de sus campos\n            rows.append(val)\n        # si es objeto tipo Document (atributos .page_content, .metadata)\n        elif hasattr(val, \"page_content\"):\n          meta = getattr(val, \"metadata\", {})\n          row = {\"text\": getattr(val, \"page_content\", \"\")}\n          if isinstance(meta, dict):\n            row.update(meta)\n          rows.append(row)\n        # string / number -> texto simple\n        elif isinstance(val, (str, int, float)):\n          rows.append({\"text\": str(val)})\n        # cualquier otro -> representacin string\n        else:\n          rows.append({\"text\": str(val)})\n      df = pd.DataFrame(rows) if rows else pd.DataFrame()\n    # 4) dict individual\n    elif isinstance(raw, dict):\n      if \"page_content\" in raw:\n        row = {\"text\": raw.get(\"page_content\", \"\")}\n        meta = raw.get(\"metadata\")\n        if isinstance(meta, dict):\n          row.update(meta)\n        else:\n          row[\"metadata\"] = str(meta)\n        df = pd.DataFrame([row])\n      else:\n        df = pd.DataFrame([raw])\n    # 5) string / numeric -> 1-row DF\n    elif isinstance(raw, (str, int, float)):\n      df = pd.DataFrame([{\"text\": str(raw)}])\n    # 6) fallback: intentar str()\n    else:\n      df = pd.DataFrame([{\"text\": str(raw)}])\n    # Aseguramos la columna 'text'\n    if \"text\" not in df.columns:\n      if \"page_content\" in df.columns:\n        df[\"text\"] = df[\"page_content\"]\n      else:\n        # si existe alguna columna que parezca contener texto, intentar usarla\n        possible_text_cols = [c for c in df.columns if df[c].dtype == object]\n        if possible_text_cols:\n          df[\"text\"] = df[possible_text_cols[0]].astype(str)\n        else:\n          df[\"text\"] = \"\"\n    return df\n  # ---------- Output method ----------\n  def df_response(self) -> pd.DataFrame:\n    \"\"\"\n    Devuelve exactamente el input_dataframe si la condicin es True.\n    Si la condicin es False devuelve un DataFrame vaco.\n    \"\"\"\n    try:\n      result = self.evaluate_condition(\n        self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n      )\n    except Exception as e:\n      self.status = f\"Error evaluando condicin: {e}\"\n      return pd.DataFrame()\n    if not result:\n      self.status = \"Condicin evaluada como False -> devolviendo DataFrame vaco.\"\n      return pd.DataFrame()\n    # Si es True, devolvemos exactamente el input recibido\n    if hasattr(self, \"input_dataframe\"):\n      raw = self.input_dataframe\n      # Si es wrapper Data, tomamos .value\n      if hasattr(raw, \"value\"):\n        return raw.value\n      return raw\n    # fallback\n    return pd.DataFrame()"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "false_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case False",
                "dynamic": false,
                "info": "The message to pass if the condition is False.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "false_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_dataframe": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Input DataFrame",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_dataframe",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "GITHUB_INGESTED"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex",
                  "less than",
                  "less than or equal",
                  "greater than",
                  "greater than or equal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              },
              "true_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case True",
                "dynamic": false,
                "info": "The message to pass if the condition is True.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "true_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-92JKj",
        "measured": {
          "height": 515,
          "width": 320
        },
        "position": {
          "x": 1086.764337561137,
          "y": -193.15634825680021
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-KRmEh",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, _icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-KRmEh",
        "measured": {
          "height": 165,
          "width": 320
        },
        "position": {
          "x": 2876.1846209841165,
          "y": 270.15978596358053
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "JigsawStackAISearch-OqFI6",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Effortlessly search the Web and get access to high-quality results powered with AI.",
            "display_name": "AI Web Search",
            "documentation": "https://jigsawstack.com/docs/api-reference/web/ai-search",
            "edited": true,
            "field_order": [
              "api_key",
              "query",
              "ai_overview",
              "safe_search",
              "spell_check",
              "number_of_results"
            ],
            "frozen": false,
            "icon": "JigsawStack",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "AI Search Results",
                "group_outputs": false,
                "hidden": null,
                "method": "search",
                "name": "search_results",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Content Text",
                "group_outputs": false,
                "hidden": null,
                "method": "get_content_text",
                "name": "content_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "ai_overview": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "AI Overview",
                "dynamic": false,
                "info": "Include AI powered overview in the search results",
                "list": false,
                "list_add_label": "Add More",
                "name": "ai_overview",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "JigsawStack API Key",
                "dynamic": false,
                "info": "Your JigsawStack API key for authentication",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\r\nfrom langflow.io import BoolInput, DropdownInput, IntInput, Output, QueryInput, SecretStrInput\r\nfrom langflow.schema.data import Data\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass JigsawStackAIWebSearchComponent(Component):\r\n    display_name = \"AI Web Search\"\r\n    description = \"Effortlessly search the Web and get access to high-quality results powered with AI.\"\r\n    documentation = \"https://jigsawstack.com/docs/api-reference/web/ai-search\"\r\n    icon = \"JigsawStack\"\r\n    name = \"JigsawStackAISearch\"\r\n\r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"JigsawStack API Key\",\r\n            info=\"Your JigsawStack API key for authentication\",\r\n            required=True,\r\n        ),\r\n        QueryInput(\r\n            name=\"query\",\r\n            display_name=\"Query\",\r\n            info=\"The search value. The maximum query character length is 400\",\r\n            required=True,\r\n            tool_mode=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"ai_overview\",\r\n            display_name=\"AI Overview\",\r\n            info=\"Include AI powered overview in the search results\",\r\n            required=False,\r\n            value=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"safe_search\",\r\n            display_name=\"Safe Search\",\r\n            info=\"Enable safe search to filter out adult content\",\r\n            required=False,\r\n            options=[\"moderate\", \"strict\", \"off\"],\r\n            value=\"off\",\r\n        ),\r\n        BoolInput(\r\n            name=\"spell_check\",\r\n            display_name=\"Spell Check\",\r\n            info=\"Spell check the search query\",\r\n            required=False,\r\n            value=True,\r\n        ),\r\n        IntInput(\r\n            name=\"number_of_results\",\r\n            display_name=\"Number of Results\",\r\n            info=\"Number of results to return.\",\r\n            required=True,\r\n            value=3,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"AI Search Results\", name=\"search_results\", method=\"search\"),\r\n        Output(display_name=\"Content Text\", name=\"content_text\", method=\"get_content_text\"),\r\n    ]\r\n\r\n    def _execute_search(self):\r\n        \"\"\"Método auxiliar para ejecutar la llamada a la API y manejar la importación.\"\"\"\r\n        try:\r\n            from jigsawstack import JigsawStack, JigsawStackError\r\n        except ImportError as e:\r\n            raise ImportError(\r\n                \"JigsawStack package not found. Install it with: pip install jigsawstack>=0.2.7\"\r\n            ) from e\r\n\r\n        client = JigsawStack(api_key=self.api_key)\r\n\r\n        # build request object\r\n        search_params = {\r\n            \"query\": self.query,\r\n            \"ai_overview\": self.ai_overview,\r\n            \"safe_search\": self.safe_search,\r\n            \"spell_check\": self.spell_check,\r\n        }\r\n        if self.number_of_results:\r\n            # La API de JigsawStack usa 'max_results'\r\n            search_params[\"max_results\"] = self.number_of_results\r\n\r\n        try:\r\n            response = client.web.search(search_params)\r\n            \r\n            if not response.get(\"success\", False):\r\n                raise ValueError(\"JigsawStack API returned unsuccessful response\")\r\n\r\n            return response, JigsawStackError\r\n            \r\n        except JigsawStackError as e:\r\n            # Re-lanzar o manejar el error en los métodos de salida\r\n            raise e\r\n        except Exception as e:\r\n            raise e\r\n\r\n    def search(self) -> Data:\r\n        \"\"\"Devuelve el objeto Data completo con los resultados de la búsqueda.\"\"\"\r\n        try:\r\n            response, JigsawStackError = self._execute_search()\r\n        except ImportError as e:\r\n            return Data(data={\"error\": str(e), \"success\": False})\r\n        except Exception as e:\r\n            self.status = f\"Error: {e!s}\"\r\n            return Data(data={\"error\": str(e), \"success\": False})\r\n\r\n        # Obtener los resultados y aplicar el CORTE EXPLÍCITO para asegurar la limitación.\r\n        results = response.get(\"results\", [])\r\n        # Aplica el slice para limitar la cantidad total de resultados (la corrección clave)\r\n        results = results[:self.number_of_results]\r\n\r\n        # Limitar links a máximo 3 por resultado\r\n        for r in results:\r\n            if \"links\" in r:\r\n                r[\"links\"] = r[\"links\"][:3]\r\n\r\n        result_data = {\r\n            \"query\": self.query,\r\n            \"ai_overview\": response.get(\"ai_overview\", \"\"),\r\n            \"spell_fixed\": response.get(\"spell_fixed\", False),\r\n            \"is_safe\": response.get(\"is_safe\", True),\r\n            \"results\": results, # Usamos la lista de resultados ya limitada\r\n            \"success\": True,\r\n        }\r\n\r\n        self.status = f\"Search complete for: {response.get('query', '')}\"\r\n        return Data(data=result_data)\r\n\r\n    def get_content_text(self) -> Message:\r\n        \"\"\"Devuelve solo el AI Overview como texto (formato Message).\"\"\"\r\n        try:\r\n            response, JigsawStackError = self._execute_search()\r\n        except ImportError:\r\n            return Message(text=\"Error: JigsawStack package not found.\")\r\n        except JigsawStackError as e:\r\n            return Message(text=f\"Error while using AI Search: {e!s}\")\r\n        except Exception as e:\r\n            return Message(text=f\"An unexpected error occurred: {e!s}\")\r\n\r\n        # La limitación de resultados se aplica en _execute_search si la API lo respeta\r\n        # y se vuelve a aplicar en 'search'. Para 'get_content_text' solo necesitamos\r\n        # el 'ai_overview'.\r\n\r\n        # Devolver solo el AI overview como texto\r\n        content = response.get(\"ai_overview\", \"\")\r\n        return Message(text=content)"
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "query": {
                "_input_type": "QueryInput",
                "advanced": false,
                "display_name": "Query",
                "dynamic": false,
                "info": "The search value. The maximum query character length is 400",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "query",
                "value": ""
              },
              "safe_search": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Safe Search",
                "dynamic": false,
                "info": "Enable safe search to filter out adult content",
                "name": "safe_search",
                "options": [
                  "moderate",
                  "strict",
                  "off"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "off"
              },
              "spell_check": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Spell Check",
                "dynamic": false,
                "info": "Spell check the search query",
                "list": false,
                "list_add_label": "Add More",
                "name": "spell_check",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "selected_output": "search_results",
          "showNode": true,
          "type": "JigsawStackAISearch"
        },
        "dragging": false,
        "id": "JigsawStackAISearch-OqFI6",
        "measured": {
          "height": 549,
          "width": 320
        },
        "position": {
          "x": 696.993598571217,
          "y": -758.3045202678863
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -135.5989661769728,
      "y": 608.6108143781994,
      "zoom": 0.7595235897831096
    }
  },
  "description": "Load your data for chat context with Retrieval Augmented Generation.",
  "endpoint_name": "retriever_flow",
  "id": "33e2a7a7-9930-4aec-b60d-ee63c0c8aee5",
  "is_component": false,
  "last_tested_version": "1.5.1",
  "name": "Retriever Flow",
  "tags": [
    "openai",
    "astradb",
    "rag",
    "q-a"
  ]
}