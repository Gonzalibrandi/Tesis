{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MetadataTagger",
            "id": "MetadataTagger-XqRJY",
            "name": "tagged_documents",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_documents",
            "id": "CustomComponent-F1TVs",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__MetadataTagger-XqRJY{œdataTypeœ:œMetadataTaggerœ,œidœ:œMetadataTagger-XqRJYœ,œnameœ:œtagged_documentsœ,œoutput_typesœ:[œDataœ]}-CustomComponent-F1TVs{œfieldNameœ:œinput_documentsœ,œidœ:œCustomComponent-F1TVsœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "MetadataTagger-XqRJY",
        "sourceHandle": "{œdataTypeœ:œMetadataTaggerœ,œidœ:œMetadataTagger-XqRJYœ,œnameœ:œtagged_documentsœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-F1TVs",
        "targetHandle": "{œfieldNameœ:œinput_documentsœ,œidœ:œCustomComponent-F1TVsœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-TzwXF",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "Chroma-sNqsV",
            "inputTypes": [
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__SplitText-TzwXF{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-TzwXFœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-Chroma-sNqsV{œfieldNameœ:œingest_dataœ,œidœ:œChroma-sNqsVœ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SplitText-TzwXF",
        "sourceHandle": "{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-TzwXFœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "Chroma-sNqsV",
        "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œChroma-sNqsVœ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DocumentNormalizer",
            "id": "CustomComponent-F1TVs",
            "name": "normalized_documents",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-TzwXF",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-F1TVs{œdataTypeœ:œDocumentNormalizerœ,œidœ:œCustomComponent-F1TVsœ,œnameœ:œnormalized_documentsœ,œoutput_typesœ:[œDataœ]}-SplitText-TzwXF{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-TzwXFœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-F1TVs",
        "sourceHandle": "{œdataTypeœ:œDocumentNormalizerœ,œidœ:œCustomComponent-F1TVsœ,œnameœ:œnormalized_documentsœ,œoutput_typesœ:[œDataœ]}",
        "target": "SplitText-TzwXF",
        "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-TzwXFœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GitExtractorComponent",
            "id": "GitExtractorComponent-PmJhm",
            "name": "files_content",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_documents",
            "id": "MetadataTagger-XqRJY",
            "inputTypes": [
              "Data",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__GitExtractorComponent-PmJhm{œdataTypeœ:œGitExtractorComponentœ,œidœ:œGitExtractorComponent-PmJhmœ,œnameœ:œfiles_contentœ,œoutput_typesœ:[œDataœ]}-MetadataTagger-XqRJY{œfieldNameœ:œinput_documentsœ,œidœ:œMetadataTagger-XqRJYœ,œinputTypesœ:[œDataœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "GitExtractorComponent-PmJhm",
        "sourceHandle": "{œdataTypeœ:œGitExtractorComponentœ,œidœ:œGitExtractorComponent-PmJhmœ,œnameœ:œfiles_contentœ,œoutput_typesœ:[œDataœ]}",
        "target": "MetadataTagger-XqRJY",
        "targetHandle": "{œfieldNameœ:œinput_documentsœ,œidœ:œMetadataTagger-XqRJYœ,œinputTypesœ:[œDataœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "NVIDIAEmbeddingsComponent",
            "id": "NVIDIAEmbeddingsComponent-UXH2O",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "Chroma-sNqsV",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__NVIDIAEmbeddingsComponent-UXH2O{œdataTypeœ:œNVIDIAEmbeddingsComponentœ,œidœ:œNVIDIAEmbeddingsComponent-UXH2Oœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-Chroma-sNqsV{œfieldNameœ:œembeddingœ,œidœ:œChroma-sNqsVœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "NVIDIAEmbeddingsComponent-UXH2O",
        "sourceHandle": "{œdataTypeœ:œNVIDIAEmbeddingsComponentœ,œidœ:œNVIDIAEmbeddingsComponent-UXH2Oœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "Chroma-sNqsV",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œChroma-sNqsVœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "SplitText-TzwXF",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Split text into chunks based on specified criteria.",
            "display_name": "Split Text",
            "documentation": "https://docs.langflow.org/components-processing#split-text",
            "edited": true,
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator",
              "text_key",
              "keep_separator"
            ],
            "frozen": false,
            "icon": "scissors-line-dashed",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks",
                "group_outputs": false,
                "hidden": null,
                "method": "split_text",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_overlap": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Chunk Overlap",
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chunk_overlap",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 50
              },
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "The maximum length of each chunk. Text is first split by separator, then chunks are merged up to this size. Individual splits larger than this won't be further divided.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 512
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import DropdownInput, HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#split-text\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Input\",\n            info=\"The data with texts to split in chunks.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=(\n                \"The maximum length of each chunk. Text is first split by separator, \"\n                \"then chunks are merged up to this size. \"\n                \"Individual splits larger than this won't be further divided.\"\n            ),\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=(\n                \"The character to split on. Use \\\\n for newline. \"\n                \"Examples: \\\\n\\\\n for paragraphs, \\\\n for lines, . for sentences\"\n            ),\n            value=\"\\n\",\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key to use for the text column.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"keep_separator\",\n            display_name=\"Keep Separator\",\n            info=\"Whether to keep the separator in the output chunks and where to place it.\",\n            options=[\"False\", \"True\", \"Start\", \"End\"],\n            value=\"False\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"dataframe\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs) -> list[Data]:\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def _fix_separator(self, separator: str) -> str:\n        \"\"\"Fix common separator issues and convert to proper format.\"\"\"\n        if separator == \"/n\":\n            return \"\\n\"\n        if separator == \"/t\":\n            return \"\\t\"\n        return separator\n\n    def split_text_base(self):\n        separator = self._fix_separator(self.separator)\n        separator = unescape_string(separator)\n\n        if isinstance(self.data_inputs, DataFrame):\n            if not len(self.data_inputs):\n                msg = \"DataFrame is empty\"\n                raise TypeError(msg)\n\n            self.data_inputs.text_key = self.text_key\n            try:\n                documents = self.data_inputs.to_lc_documents()\n            except Exception as e:\n                msg = f\"Error converting DataFrame to documents: {e}\"\n                raise TypeError(msg) from e\n        elif isinstance(self.data_inputs, Message):\n            self.data_inputs = [self.data_inputs.to_data()]\n            return self.split_text_base()\n        else:\n            if not self.data_inputs:\n                msg = \"No data inputs provided\"\n                raise TypeError(msg)\n\n            documents = []\n            if isinstance(self.data_inputs, Data):\n                self.data_inputs.text_key = self.text_key\n                documents = [self.data_inputs.to_lc_document()]\n            else:\n                try:\n                    documents = [input_.to_lc_document() for input_ in self.data_inputs if isinstance(input_, Data)]\n                    if not documents:\n                        msg = f\"No valid Data inputs found in {type(self.data_inputs)}\"\n                        raise TypeError(msg)\n                except AttributeError as e:\n                    msg = f\"Invalid input type in collection: {e}\"\n                    raise TypeError(msg) from e\n        try:\n            # Convert string 'False'/'True' to boolean\n            keep_sep = self.keep_separator\n            if isinstance(keep_sep, str):\n                if keep_sep.lower() == \"false\":\n                    keep_sep = False\n                elif keep_sep.lower() == \"true\":\n                    keep_sep = True\n                # 'start' and 'end' are kept as strings\n\n            splitter = RecursiveCharacterTextSplitter(\n                chunk_overlap=self.chunk_overlap,\n                chunk_size=self.chunk_size,\n                separators=[self.separator, \"\\n\\n\", \" \", \"\"], # Lista de separadores de respaldo\n                keep_separator=keep_sep,\n            )\n            return splitter.split_documents(documents)\n        except Exception as e:\n            msg = f\"Error splitting text: {e}\"\n            raise TypeError(msg) from e\n\n    def split_text(self) -> DataFrame:\n        docs = self.split_text_base()\n        records = [{\"text\": doc.page_content, \"metadata\": doc.metadata} for doc in docs]\n        pd_df = pd.DataFrame(records)\n        return DataFrame(data=pd_df)\n"
              },
              "data_inputs": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The data with texts to split in chunks.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data_inputs",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keep_separator": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Keep Separator",
                "dynamic": false,
                "info": "Whether to keep the separator in the output chunks and where to place it.",
                "name": "keep_separator",
                "options": [
                  "False",
                  "True",
                  "Start",
                  "End"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "False"
              },
              "separator": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Separator",
                "dynamic": false,
                "info": "The character to split on. Use \\n for newline. Examples: \\n\\n for paragraphs, \\n for lines, . for sentences",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "text_key": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Key",
                "dynamic": false,
                "info": "The key to use for the text column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "content"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SplitText"
        },
        "dragging": false,
        "id": "SplitText-TzwXF",
        "measured": {
          "height": 409,
          "width": 320
        },
        "position": {
          "x": 770.3566808601587,
          "y": -53.79353537180149
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GitExtractorComponent-PmJhm",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "category": "git",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Analyzes a Git repository and returns file contents and complete repository information",
            "display_name": "GitExtractor",
            "documentation": "",
            "edited": false,
            "field_order": [
              "repository_url"
            ],
            "frozen": false,
            "icon": "GitLoader",
            "key": "GitExtractorComponent",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Text-Based File Contents",
                "group_outputs": false,
                "method": "get_text_based_file_contents",
                "name": "text_based_file_contents",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Directory Structure",
                "group_outputs": false,
                "method": "get_directory_structure",
                "name": "directory_structure",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Repository Info",
                "group_outputs": false,
                "method": "get_repository_info",
                "name": "repository_info",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Statistics",
                "group_outputs": false,
                "method": "get_statistics",
                "name": "statistics",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Files Content",
                "group_outputs": false,
                "method": "get_files_content",
                "name": "files_content",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 1.1732828199964098e-19,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\nimport shutil\nimport tempfile\nfrom contextlib import asynccontextmanager\nfrom pathlib import Path\n\nimport aiofiles\nimport git\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\n\n\nclass GitExtractorComponent(Component):\n    display_name = \"GitExtractor\"\n    description = \"Analyzes a Git repository and returns file contents and complete repository information\"\n    icon = \"GitLoader\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"repository_url\",\n            display_name=\"Repository URL\",\n            info=\"URL of the Git repository (e.g., https://github.com/username/repo)\",\n            value=\"\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Text-Based File Contents\",\n            name=\"text_based_file_contents\",\n            method=\"get_text_based_file_contents\",\n        ),\n        Output(display_name=\"Directory Structure\", name=\"directory_structure\", method=\"get_directory_structure\"),\n        Output(display_name=\"Repository Info\", name=\"repository_info\", method=\"get_repository_info\"),\n        Output(display_name=\"Statistics\", name=\"statistics\", method=\"get_statistics\"),\n        Output(display_name=\"Files Content\", name=\"files_content\", method=\"get_files_content\"),\n    ]\n\n    @asynccontextmanager\n    async def temp_git_repo(self):\n        \"\"\"Async context manager for temporary git repository cloning.\"\"\"\n        temp_dir = tempfile.mkdtemp()\n        try:\n            # Clone is still sync but wrapped in try/finally\n            git.Repo.clone_from(self.repository_url, temp_dir)\n            yield temp_dir\n        finally:\n            shutil.rmtree(temp_dir, ignore_errors=True)\n\n    async def get_repository_info(self) -> list[Data]:\n        try:\n            async with self.temp_git_repo() as temp_dir:\n                repo = git.Repo(temp_dir)\n                repo_info = {\n                    \"name\": self.repository_url.split(\"/\")[-1],\n                    \"url\": self.repository_url,\n                    \"default_branch\": repo.active_branch.name,\n                    \"remote_urls\": [remote.url for remote in repo.remotes],\n                    \"last_commit\": {\n                        \"hash\": repo.head.commit.hexsha,\n                        \"author\": str(repo.head.commit.author),\n                        \"message\": repo.head.commit.message.strip(),\n                        \"date\": str(repo.head.commit.committed_datetime),\n                    },\n                    \"branches\": [str(branch) for branch in repo.branches],\n                }\n                result = [Data(data=repo_info)]\n                self.status = result\n                return result\n        except git.GitError as e:\n            error_result = [Data(data={\"error\": f\"Error getting repository info: {e!s}\"})]\n            self.status = error_result\n            return error_result\n\n    async def get_statistics(self) -> list[Data]:\n        try:\n            async with self.temp_git_repo() as temp_dir:\n                total_files = 0\n                total_size = 0\n                total_lines = 0\n                binary_files = 0\n                directories = 0\n\n                for root, dirs, files in os.walk(temp_dir):\n                    total_files += len(files)\n                    directories += len(dirs)\n                    for file in files:\n                        file_path = Path(root) / file\n                        total_size += file_path.stat().st_size\n                        try:\n                            async with aiofiles.open(file_path, encoding=\"utf-8\") as f:\n                                total_lines += sum(1 for _ in await f.readlines())\n                        except UnicodeDecodeError:\n                            binary_files += 1\n\n                statistics = {\n                    \"total_files\": total_files,\n                    \"total_size_bytes\": total_size,\n                    \"total_size_kb\": round(total_size / 1024, 2),\n                    \"total_size_mb\": round(total_size / (1024 * 1024), 2),\n                    \"total_lines\": total_lines,\n                    \"binary_files\": binary_files,\n                    \"directories\": directories,\n                }\n                result = [Data(data=statistics)]\n                self.status = result\n                return result\n        except git.GitError as e:\n            error_result = [Data(data={\"error\": f\"Error calculating statistics: {e!s}\"})]\n            self.status = error_result\n            return error_result\n\n    async def get_directory_structure(self) -> Message:\n        try:\n            async with self.temp_git_repo() as temp_dir:\n                tree = [\"Directory structure:\"]\n                for root, _dirs, files in os.walk(temp_dir):\n                    level = root.replace(temp_dir, \"\").count(os.sep)\n                    indent = \"    \" * level\n                    if level == 0:\n                        tree.append(f\"└── {Path(root).name}\")\n                    else:\n                        tree.append(f\"{indent}├── {Path(root).name}\")\n                    subindent = \"    \" * (level + 1)\n                    tree.extend(f\"{subindent}├── {f}\" for f in files)\n                directory_structure = \"\\n\".join(tree)\n                self.status = directory_structure\n                return Message(text=directory_structure)\n        except git.GitError as e:\n            error_message = f\"Error getting directory structure: {e!s}\"\n            self.status = error_message\n            return Message(text=error_message)\n\n    async def get_files_content(self) -> list[Data]:\n        try:\n            async with self.temp_git_repo() as temp_dir:\n                content_list = []\n                for root, _, files in os.walk(temp_dir):\n                    for file in files:\n                        file_path = Path(root) / file\n                        relative_path = file_path.relative_to(temp_dir)\n                        file_size = file_path.stat().st_size\n                        try:\n                            async with aiofiles.open(file_path, encoding=\"utf-8\") as f:\n                                file_content = await f.read()\n                        except UnicodeDecodeError:\n                            file_content = \"[BINARY FILE]\"\n                        content_list.append(\n                            Data(data={\"path\": str(relative_path), \"size\": file_size, \"content\": file_content})\n                        )\n                self.status = content_list\n                return content_list\n        except git.GitError as e:\n            error_result = [Data(data={\"error\": f\"Error getting files content: {e!s}\"})]\n            self.status = error_result\n            return error_result\n\n    async def get_text_based_file_contents(self) -> Message:\n        try:\n            async with self.temp_git_repo() as temp_dir:\n                content_list = [\"(Files content cropped to 300k characters, download full ingest to see more)\"]\n                total_chars = 0\n                char_limit = 300000\n\n                for root, _, files in os.walk(temp_dir):\n                    for file in files:\n                        file_path = Path(root) / file\n                        relative_path = file_path.relative_to(temp_dir)\n                        content_list.extend([\"=\" * 50, f\"File: /{relative_path}\", \"=\" * 50])\n\n                        try:\n                            async with aiofiles.open(file_path, encoding=\"utf-8\") as f:\n                                file_content = await f.read()\n                                if total_chars + len(file_content) > char_limit:\n                                    remaining_chars = char_limit - total_chars\n                                    file_content = file_content[:remaining_chars] + \"\\n... (content truncated)\"\n                                content_list.append(file_content)\n                                total_chars += len(file_content)\n                        except UnicodeDecodeError:\n                            content_list.append(\"[BINARY FILE]\")\n\n                        content_list.append(\"\")\n\n                        if total_chars >= char_limit:\n                            break\n\n                text_content = \"\\n\".join(content_list)\n                self.status = text_content\n                return Message(text=text_content)\n        except git.GitError as e:\n            error_message = f\"Error getting text-based file contents: {e!s}\"\n            self.status = error_message\n            return Message(text=error_message)\n"
              },
              "repository_url": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Repository URL",
                "dynamic": false,
                "info": "URL of the Git repository (e.g., https://github.com/username/repo)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "repository_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "files_content",
          "showNode": true,
          "type": "GitExtractorComponent"
        },
        "dragging": false,
        "id": "GitExtractorComponent-PmJhm",
        "measured": {
          "height": 218,
          "width": 320
        },
        "position": {
          "x": -322.3868788512631,
          "y": -127.93685628511645
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MetadataTagger-XqRJY",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Adds a custom key-value pair to the metadata of each document in a list.",
            "display_name": "Metadata Tagger",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_documents",
              "tag_name",
              "tag_value"
            ],
            "frozen": false,
            "icon": "tag",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Tagged Documents",
                "group_outputs": false,
                "hidden": null,
                "method": "tag_documents",
                "name": "tagged_documents",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import List\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data, Message\r\n\r\nclass MetadataTagger(Component):\r\n    display_name = \"Metadata Tagger\"\r\n    description = \"Adds a custom key-value pair to the metadata of each document in a list.\"\r\n    icon = \"tag\"\r\n    name = \"MetadataTagger\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"input_documents\",\r\n            display_name=\"Input Data\",\r\n            info=\"The documents to tag. Can be a list of Data or a Message containing a list of Data.\",\r\n            is_list=True,\r\n            # --- CAMBIO IMPORTANTE: Aceptamos también objetos Message ---\r\n            input_types=[\"Data\", \"Message\"],\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"tag_name\",\r\n            display_name=\"Tag Name\",\r\n            info=\"The name of the metadata field to add (e.g., 'origin').\",\r\n            value=\"origin\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"tag_value\",\r\n            display_name=\"Tag Value\",\r\n            info=\"The value to assign to the tag (e.g., 'PDF Document').\",\r\n            value=\"Unknown\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Tagged Documents\",\r\n            name=\"tagged_documents\",\r\n            method=\"tag_documents\"\r\n        ),\r\n    ]\r\n\r\n    def tag_documents(self) -> List[Data]:\r\n        \"\"\"\r\n        Extracts documents from the input and adds the specified tag to their metadata.\r\n        \"\"\"\r\n        raw_input = self.input_documents or []\r\n        documents: List[Data] = []\r\n        \r\n        # --- CAMBIO IMPORTANTE: Lógica para \"desenvolver\" la entrada ---\r\n        # Si la entrada es un Message, extraemos su contenido.\r\n        if isinstance(raw_input, Message):\r\n            content = raw_input.content\r\n            if isinstance(content, list):\r\n                documents = content\r\n            elif isinstance(content, Data):\r\n                documents = [content]\r\n        # Si ya es una lista (de Data), la usamos directamente.\r\n        elif isinstance(raw_input, list):\r\n            documents = raw_input\r\n        # Si es un solo objeto Data, lo metemos en una lista.\r\n        elif isinstance(raw_input, Data):\r\n            documents = [raw_input]\r\n\r\n        tag_name = self.tag_name\r\n        tag_value = self.tag_value\r\n        \r\n        if not documents:\r\n            self.status = \"No valid documents found in the input to tag.\"\r\n            return []\r\n\r\n        tagged_docs = []\r\n        for doc in documents:\r\n            if isinstance(doc, Data):\r\n                if not hasattr(doc, 'metadata') or not isinstance(doc.metadata, dict):\r\n                    doc.metadata = {}\r\n                \r\n                doc.metadata[tag_name] = tag_value\r\n                tagged_docs.append(doc)\r\n\r\n        self.status = f\"Successfully tagged {len(tagged_docs)} documents with '{tag_name}: {tag_value}'.\"\r\n        return tagged_docs"
              },
              "input_documents": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input Data",
                "dynamic": false,
                "info": "The documents to tag. Can be a list of Data or a Message containing a list of Data.",
                "input_types": [
                  "Data",
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "input_documents",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "tag_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Tag Name",
                "dynamic": false,
                "info": "The name of the metadata field to add (e.g., 'origin').",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tag_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "origin"
              },
              "tag_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Tag Value",
                "dynamic": false,
                "info": "The value to assign to the tag (e.g., 'PDF Document').",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tag_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "GitHub Repository"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MetadataTagger"
        },
        "dragging": false,
        "id": "MetadataTagger-XqRJY",
        "measured": {
          "height": 344,
          "width": 320
        },
        "position": {
          "x": 66.72295824131362,
          "y": -106.69739925207556
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-F1TVs",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Restructures nested Data objects from loaders into a flat format for splitters.",
            "display_name": "Document Normalizer",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_documents"
            ],
            "frozen": false,
            "icon": "transform",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Normalized Documents",
                "group_outputs": false,
                "hidden": null,
                "method": "normalize_documents",
                "name": "normalized_documents",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import List\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output\nfrom langflow.schema import Data\n\nclass DocumentNormalizer(Component):\n    display_name = \"Document Normalizer\"\n    description = \"Restructures nested Data objects from loaders into a flat format for splitters.\"\n    icon = \"transform\"\n    name = \"DocumentNormalizer\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_documents\",\n            display_name=\"Input Documents\",\n            info=\"The list of nested documents from a loader (e.g., GitExtractor).\",\n            is_list=True,\n            input_types=[\"Data\"],\n            required=True,\n        )\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Normalized Documents\",\n            name=\"normalized_documents\",\n            method=\"normalize_documents\"\n        ),\n    ]\n\n    def normalize_documents(self) -> List[Data]:\n        \"\"\"\n        Takes nested Data objects and flattens them into the standard format\n        that splitters and other components expect.\n        \"\"\"\n        nested_docs = self.input_documents or []\n        normalized_docs = []\n\n        if not nested_docs:\n            self.status = \"No documents to normalize.\"\n            return []\n\n        for doc in nested_docs:\n            # Nos aseguramos de que el objeto tenga la estructura anidada que esperamos\n            if not isinstance(doc, Data) or not hasattr(doc, 'data') or not doc.data:\n                continue\n\n            # Extraemos la información de la sub-caja '.data'\n            inner_data = doc.data\n            content = inner_data.get(\"content\", \"\")\n            path = inner_data.get(\"path\", \"Unknown Path\")\n            \n            # Extraemos los metadatos de la sub-sub-caja '.data['metadata']'\n            inner_metadata = inner_data.get(\"metadata\", {})\n            origin = inner_metadata.get(\"origin\", \"Unknown Origin\")\n            \n            # Creamos un nuevo objeto Data con la estructura \"plana\" y correcta\n            new_doc = Data(\n                text=content,\n                metadata={\n                    \"source\": path,  # Usamos 'path' como la 'source'\n                    \"origin\": origin   # Propagamos el 'origin' que agregamos antes\n                }\n            )\n            normalized_docs.append(new_doc)\n            \n        self.status = f\"Successfully normalized {len(normalized_docs)} documents.\"\n        return normalized_docs\n"
              },
              "input_documents": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input Documents",
                "dynamic": false,
                "info": "The list of nested documents from a loader (e.g., GitExtractor).",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "input_documents",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DocumentNormalizer"
        },
        "dragging": false,
        "id": "CustomComponent-F1TVs",
        "measured": {
          "height": 180,
          "width": 320
        },
        "position": {
          "x": 427.0579630245183,
          "y": 39.42433807176252
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Chroma-sNqsV",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Chroma Vector Store with search capabilities",
            "display_name": "Chroma DB",
            "documentation": "",
            "edited": true,
            "field_order": [
              "collection_name",
              "persist_directory",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "embedding",
              "chroma_server_cors_allow_origins",
              "chroma_server_host",
              "chroma_server_http_port",
              "chroma_server_grpc_port",
              "chroma_server_ssl_enabled",
              "allow_duplicates",
              "search_type",
              "number_of_results",
              "limit",
              "clear_collection"
            ],
            "frozen": false,
            "icon": "Chroma",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "group_outputs": false,
                "hidden": null,
                "method": "search_documents",
                "name": "search_results",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "hidden": null,
                "method": "as_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "allow_duplicates": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Allow Duplicates",
                "dynamic": false,
                "info": "If false, will not add documents that are already in the Vector Store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "allow_duplicates",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "chroma_server_cors_allow_origins": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Server CORS Allow Origins",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chroma_server_cors_allow_origins",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chroma_server_grpc_port": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Server gRPC Port",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "chroma_server_grpc_port",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "chroma_server_host": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Server Host",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chroma_server_host",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chroma_server_http_port": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Server HTTP Port",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "chroma_server_http_port",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "chroma_server_ssl_enabled": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Server SSL Enabled",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "chroma_server_ssl_enabled",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "clear_collection": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Clear Collection Before Ingest",
                "dynamic": false,
                "info": "If True, deletes the entire collection before adding new documents. Guarantees a clean slate.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clear_collection",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma import Chroma\nfrom typing_extensions import override\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.base.vectorstores.utils import chroma_collection_to_data\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, IntInput, StrInput\nfrom langflow.schema.data import Data\n\nif TYPE_CHECKING:\n    from langflow.schema.dataframe import DataFrame\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"Chroma Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    name = \"Chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"langflow\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n        BoolInput(\n            name=\"clear_collection\",\n            display_name=\"Clear Collection Before Ingest\",\n            info=\"If True, deletes the entire collection before adding new documents. Guarantees a clean slate.\",\n            value=True, # Por defecto, borra.\n            advanced=True,\n        ),\n    ]\n\n    @override\n    @check_cached_vector_store\n    def build_vector_store(self) -> Chroma:\n        \"\"\"Builds the Chroma object.\"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError as e:\n            msg = \"Could not import Chroma integration package. Please install it with `pip install langchain-chroma`.\"\n            raise ImportError(msg) from e\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        persist_directory = self.resolve_path(self.persist_directory) if self.persist_directory is not None else None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n        \n        if self.clear_collection and self.ingest_data:\n            self.log(f\"Clearing collection '{self.collection_name}' before ingestion.\")\n            try:\n                # Usamos la instancia para borrar la colección\n                chroma.delete_collection()\n                \n                # ¡CRUCIAL! Volvemos a crear el objeto `Chroma`.\n                # Esto fuerza a la librería a empezar con una colección nueva y vacía.\n                chroma = Chroma(\n                    persist_directory=persist_directory,\n                    embedding_function=self.embedding,\n                    collection_name=self.collection_name,\n                )\n            except Exception as e:\n                self.log(f\"Could not delete collection (it might not exist yet): {e}\")\n\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"Adds documents to the Vector Store.\"\"\"\n        ingest_data: list | Data | DataFrame = self.ingest_data\n        if not ingest_data:\n            self.status = \"\"\n            return\n    \n        # Convert DataFrame to Data if needed using parent's method\n        ingest_data = self._prepare_ingest_data()\n        \n        stored_documents_without_id = []\n        stored_data = chroma_collection_to_data(vector_store.get(limit=self.limit))\n        for value in deepcopy(stored_data):\n            del value.id\n            stored_documents_without_id.append(value)\n    \n        documents = []\n        for _input in ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in stored_documents_without_id:\n                    # --- INICIO DEL CAMBIO DE APLANADO ---\n                    original_meta = _input.metadata or {}\n                    final_meta = {}\n                    for key, value in original_meta.items():\n                        if isinstance(value, dict):\n                            for inner_key, inner_value in value.items():\n                                if isinstance(inner_value, (str, int, float, bool)):\n                                    final_meta[inner_key] = inner_value\n                        elif isinstance(value, (str, int, float, bool)):\n                            final_meta[key] = value\n    \n                    from langchain_core.documents import Document\n                    source_file = final_meta.get(\"source\", \"Unknown Source\")\n                    new_page_content = f\"Source File: {source_file}\\n\\n{_input.text}\"\n                    new_doc = Document(page_content=new_page_content, metadata=final_meta)\n                    documents.append(new_doc)\n                    # --- FIN DEL CAMBIO DE APLANADO ---\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n    \n        if documents and self.embedding is not None:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n    \n            # --- NUEVO BLOQUE: evitar duplicados si allow_duplicates es False ---\n            if not self.allow_duplicates:\n                try:\n                    existing = vector_store.get()\n                    existing_pairs = set()\n                    if existing and \"documents\" in existing and \"metadatas\" in existing:\n                        for doc_text, meta in zip(existing[\"documents\"], existing[\"metadatas\"]):\n                            src = meta.get(\"source\", \"Unknown Source\")\n                            existing_pairs.add((doc_text, src))\n    \n                    before = len(documents)\n                    documents = [\n                        doc for doc in documents\n                        if (doc.page_content, doc.metadata.get(\"source\", \"Unknown Source\")) not in existing_pairs\n                    ]\n                    removed = before - len(documents)\n                    if removed > 0:\n                        self.log(f\"Skipped {removed} duplicate documents (same text + source).\")\n                except Exception as e:\n                    self.log(f\"⚠️ Error checking duplicates: {e}\")\n            # --- FIN NUEVO BLOQUE ---\n    \n            if documents:\n                vector_store.add_documents(documents)\n            else:\n                self.log(\"⚠️ No new documents to add (all were duplicates).\")\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n"
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "github_collection"
              },
              "embedding": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "limit": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Limit",
                "dynamic": false,
                "info": "Limit the number of records to compare when Allow Duplicates is False.",
                "list": false,
                "list_add_label": "Add More",
                "name": "limit",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "persist_directory": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Persist Directory",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "persist_directory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "./indices/github"
              },
              "search_query": {
                "_input_type": "QueryInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_query",
                "placeholder": "Enter a query...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "query",
                "value": ""
              },
              "search_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Search Type",
                "dynamic": false,
                "info": "",
                "name": "search_type",
                "options": [
                  "Similarity",
                  "MMR"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Similarity"
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "selected_output": "search_results",
          "showNode": true,
          "type": "Chroma"
        },
        "dragging": false,
        "id": "Chroma-sNqsV",
        "measured": {
          "height": 454,
          "width": 320
        },
        "position": {
          "x": 1219.1461187578454,
          "y": 107.48568216151216
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "NVIDIAEmbeddingsComponent-UXH2O",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using NVIDIA models.",
            "display_name": "NVIDIA Embeddings",
            "documentation": "",
            "edited": true,
            "field_order": [
              "base_url",
              "nvidia_api_key",
              "temperature"
            ],
            "frozen": false,
            "icon": "NVIDIA",
            "last_updated": "2025-10-29T02:29:04.990Z",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embedding Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_embeddings",
                "name": "embeddings",
                "options": null,
                "required_inputs": null,
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "base_url": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "NVIDIA Base URL",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "base_url",
                "placeholder": "",
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://integrate.api.nvidia.com/v1"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.field_typing import Embeddings\nfrom langflow.inputs.inputs import DropdownInput, SecretStrInput\nfrom langflow.io import FloatInput, MessageTextInput\nfrom langflow.schema.dotdict import dotdict\n\n\nclass NVIDIAEmbeddingsComponent(LCEmbeddingsModel):\n    display_name: str = \"NVIDIA Embeddings\"\n    description: str = \"Generate embeddings using NVIDIA models.\"\n    icon = \"NVIDIA\"\n    model_name: str = \"nvidia/nv-embed-v1\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"NVIDIA Base URL\",\n            refresh_button=True,\n            value=\"https://integrate.api.nvidia.com/v1\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"nvidia_api_key\",\n            display_name=\"NVIDIA API Key\",\n            info=\"The NVIDIA API Key.\",\n            advanced=False,\n            value=\"NVIDIA_API_KEY\",\n            required=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Model Temperature\",\n            value=0.1,\n            advanced=True,\n        ),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"base_url\" and field_value:\n            try:\n                build_model = self.build_embeddings()\n                ids = [model.id for model in build_model.available_models]\n                build_config[\"model\"][\"options\"] = ids\n                build_config[\"model\"][\"value\"] = ids[0]\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n        except ImportError as e:\n            msg = \"Please install langchain-nvidia-ai-endpoints to use the Nvidia model.\"\n            raise ImportError(msg) from e\n        try:\n            output = NVIDIAEmbeddings(\n                model=self.model_name,\n                base_url=self.base_url,\n                temperature=self.temperature,\n                nvidia_api_key=self.nvidia_api_key,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to NVIDIA API. Error: {e}\"\n            raise ValueError(msg) from e\n        return output\n"
              },
              "nvidia_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "NVIDIA API Key",
                "dynamic": false,
                "info": "The NVIDIA API Key.",
                "input_types": [],
                "load_from_db": false,
                "name": "nvidia_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Model Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "NVIDIAEmbeddingsComponent"
        },
        "dragging": false,
        "id": "NVIDIAEmbeddingsComponent-UXH2O",
        "measured": {
          "height": 284,
          "width": 320
        },
        "position": {
          "x": 758.5715181333416,
          "y": 393.3835337475715
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 232.11088411322237,
      "y": 147.51775034477708,
      "zoom": 0.5586793257684617
    }
  },
  "description": "Navigate the Linguistic Landscape, Discover Opportunities.",
  "endpoint_name": "ingest_github_flow",
  "id": "91d343c0-8632-418c-9776-023714d12054",
  "is_component": false,
  "last_tested_version": "1.5.1",
  "name": "Ingest Github Flow",
  "tags": []
}